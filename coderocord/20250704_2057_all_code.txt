

=== ai_meeting_assistant/pyproject.toml ===
[project]
name = "ai_meeting_assistant"
version = "0.1.0"
description = "ai_meeting_assistant using crewAI"
authors = [{ name = "Your Name", email = "you@example.com" }]
requires-python = ">=3.10,<3.14"
dependencies = [
    "crewai[tools]>=0.140.0,<1.0.0",
    "langchain-openai>=0.1.0",
    "langchain-google-genai>=1.0.0",
    "python-dotenv>=1.0.0",
    "pyyaml>=6.0.0"
]

[project.scripts]
ai_meeting_assistant = "ai_meeting_assistant.main:run"
run_crew = "ai_meeting_assistant.main:run"
train = "ai_meeting_assistant.main:train"
replay = "ai_meeting_assistant.main:replay"
test = "ai_meeting_assistant.main:test"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.crewai]
type = "crew"


=== ai_meeting_assistant/README.md ===
# AiMeetingAssistant Crew

Welcome to the AiMeetingAssistant Crew project, powered by [crewAI](https://crewai.com). This template is designed to help you set up a multi-agent AI system with ease, leveraging the powerful and flexible framework provided by crewAI. Our goal is to enable your agents to collaborate effectively on complex tasks, maximizing their collective intelligence and capabilities.

## Installation

Ensure you have Python >=3.10 <3.14 installed on your system. This project uses [UV](https://docs.astral.sh/uv/) for dependency management and package handling, offering a seamless setup and execution experience.

First, if you haven't already, install uv:

```bash
pip install uv
```

Next, navigate to your project directory and install the dependencies:

(Optional) Lock the dependencies and install them by using the CLI command:
```bash
crewai install
```
### Customizing

**Add your `OPENAI_API_KEY` into the `.env` file**

- Modify `src/ai_meeting_assistant/config/agents.yaml` to define your agents
- Modify `src/ai_meeting_assistant/config/tasks.yaml` to define your tasks
- Modify `src/ai_meeting_assistant/crew.py` to add your own logic, tools and specific args
- Modify `src/ai_meeting_assistant/main.py` to add custom inputs for your agents and tasks

## Running the Project

To kickstart your crew of AI agents and begin task execution, run this from the root folder of your project:

```bash
$ crewai run
```

This command initializes the ai_meeting_assistant Crew, assembling the agents and assigning them tasks as defined in your configuration.

This example, unmodified, will run the create a `report.md` file with the output of a research on LLMs in the root folder.

## Understanding Your Crew

The ai_meeting_assistant Crew is composed of multiple AI agents, each with unique roles, goals, and tools. These agents collaborate on a series of tasks, defined in `config/tasks.yaml`, leveraging their collective skills to achieve complex objectives. The `config/agents.yaml` file outlines the capabilities and configurations of each agent in your crew.

## Support

For support, questions, or feedback regarding the AiMeetingAssistant Crew or crewAI.
- Visit our [documentation](https://docs.crewai.com)
- Reach out to us through our [GitHub repository](https://github.com/joaomdmoura/crewai)
- [Join our Discord](https://discord.com/invite/X4JWnZnxPb)
- [Chat with our docs](https://chatg.pt/DWjSBZn)

Let's create wonders together with the power and simplicity of crewAI.


=== ai_meeting_assistant/testgemini.py ===
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
import google.generativeai as genai # 用於 ListModels 檢查

# 載入環境變數
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# 再次確認 API Key 是否成功載入
print(f"API Key: {'已載入' if api_key else '未載入'}")

# 設定 Gemini API Key (對 ChatGoogleGenerativeAI 也有幫助，確保底層配置正確)
genai.configure(api_key=api_key)

print("\n--- 檢查可用的 Gemini 模型 ---")
found_target_model = False
target_model_name = "models/gemini-1.5-pro" # 你正在使用的模型
for m in genai.list_models():
    if m.name == target_model_name and "generateContent" in m.supported_generation_methods:
        print(f"✅ 模型 {target_model_name} 已找到並支援 generateContent。")
        found_target_model = True
        break
    elif m.name == target_model_name:
        print(f"❌ 模型 {target_model_name} 已找到，但**不支援** generateContent。")
        print(f"支援方法：{m.supported_generation_methods}")
        found_target_model = True
        break

if not found_target_model:
    print(f"❌ 模型 {target_model_name} 在您的 API 權限下未找到。")
    print("請確認模型名稱是否正確，或檢查區域可用性。")

print("-----------------------------\n")


# 獨立測試 ChatGoogleGenerativeAI
if found_target_model:
    try:
        print("--- 獨立測試 ChatGoogleGenerativeAI ---")
        gemini_llm_test = ChatGoogleGenerativeAI(
            model=target_model_name,
            temperature=0.3
        )
        test_message = "請用一句話介紹你自己。"
        response = gemini_llm_test.invoke(test_message) # 使用 invoke 方法
        print("✅ ChatGoogleGenerativeAI 獨立測試成功！")
        print("回應:", response.content)
        print("--------------------------------------\n")
    except Exception as e:
        print(f"❌ ChatGoogleGenerativeAI 獨立測試失敗：{e}")
        print("這表示問題可能在 LangChain 整合層或底層 Gemini API 請求本身。")
else:
    print("由於目標模型未找到或不支援，無法進行 ChatGoogleGenerativeAI 的獨立測試。")

=== ai_meeting_assistant/.gitignore ===
.env
__pycache__/
.DS_Store


=== ai_meeting_assistant/.env ===
MODEL=gpt-4o
OPENAI_API_KEY=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
GOOGLE_API_KEY=AIzaSyDZDDvhc5-iRdv_vNdM9_1fAmvKDVBoRVY

=== ai_meeting_assistant/all_code.py ===
import os
import datetime

# 設定根目錄（你要輸出的資料夾）
root_folder = './'  # ← 請改成你自己的資料夾路徑
output_file = 'all_code.txt'
output_file = f"{datetime.datetime.now().strftime('%Y%m%d_%H%M')}_{output_file}"

# 設定輸出資料夾
output_folder = './coderocord/'
os.makedirs(output_folder, exist_ok=True)
output_file = os.path.join(output_folder, output_file)

def prompt_user(path):
    rel_path = os.path.relpath(path, root_folder)
    while True:
        choice = input(f"是否要輸出 '{rel_path}' 的內容？(Y/N): ").strip().upper()
        if choice in ['Y', 'N']:
            return choice == 'Y'
        print("請輸入 Y 或 N。")

with open(output_file, 'w', encoding='utf-8') as out:
    for name in os.listdir(root_folder):
        full_path = os.path.join(root_folder, name)

        if prompt_user(full_path):
            if os.path.isfile(full_path):
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        out.write(f"\n\n=== {name} ===\n")
                        out.write(f.read())
                except Exception as e:
                    out.write(f"\n\n=== {name} ===\n")
                    out.write(f"[無法讀取此檔案: {e}]\n")

            elif os.path.isdir(full_path):
                for foldername, _, filenames in os.walk(full_path):
                    for filename in filenames:
                        file_path = os.path.join(foldername, filename)
                        rel = os.path.relpath(file_path, root_folder)
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                out.write(f"\n\n=== {rel} ===\n")
                                out.write(f.read())
                        except Exception as e:
                            out.write(f"\n\n=== {rel} ===\n")
                            out.write(f"[無法讀取此檔案: {e}]\n")

print(f"\n✅ 輸出完成，請查看 {output_file}")


=== ai_meeting_assistant/testapi.py ===
import os
import google.generativeai as genai
from dotenv import load_dotenv

# 載入 .env 取得 API Key
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# 確認 API Key 是否成功載入 (僅供測試用，實際應用時不要將金鑰直接印出)
print(f"API Key: {'已載入' if api_key else '未載入'}")

# 設定 Gemini API Key
genai.configure(api_key=api_key)

# 嘗試使用另一個已知的支援 generateContent 的模型
model = genai.GenerativeModel("gemini-1.5-pro")

response = model.generate_content("請用一句話介紹你自己")

print("✅ Gemini 回應：", response.text)

=== ai_meeting_assistant/knowledge/user_preference.txt ===
User name is John Doe.
User is an AI Engineer.
User is interested in AI Agents.
User is based in San Francisco, California.


=== ai_meeting_assistant/src/ai_meeting_assistant/__init__.py ===


=== ai_meeting_assistant/src/ai_meeting_assistant/crew.py ===
import os
import yaml
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from crewai import Agent, Task, Crew, Process

# 讀取環境變數
load_dotenv()

# ---------- 讀取 YAML ----------
def load_yaml_config(path):
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

this_dir = os.path.dirname(__file__)
agents_config = load_yaml_config(os.path.join(this_dir, "config/agents.yaml"))

# ---------- 建立 LLM ----------
try:
    openai_llm = ChatOpenAI(
        model="gpt-4o",  # 使用 .env 中定義的模型
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    print("✅ OpenAI LLM 初始化成功")
except Exception as e:
    print(f"❌ OpenAI LLM 初始化失敗: {e}")
    openai_llm = None

# 為了穩定性，暫時兩個 agent 都使用 OpenAI
try:
    openai_llm_lawyer = ChatOpenAI(
        model="gpt-4o",  # 使用相同的模型但不同的實例
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    print("✅ Lawyer OpenAI LLM 初始化成功")
except Exception as e:
    print(f"❌ Lawyer OpenAI LLM 初始化失敗: {e}")
    openai_llm_lawyer = None

# Gemini LLM 暫時作為備用
try:
    gemini_llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",  # 簡化模型名稱
        temperature=0.3,
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    print("✅ Gemini LLM 初始化成功")
except Exception as e:
    print(f"❌ Gemini LLM 初始化失敗: {e}")
    gemini_llm = None

# ---------- 建立 Agents ----------
agents = {}

# 會計師使用 OpenAI
if openai_llm is not None:
    agents["accountant"] = Agent(
        config=agents_config["accountant"],
        llm=openai_llm,
        verbose=True
    )
    print("✅ Accountant agent 創建成功")
else:
    print("❌ 無法創建 Accountant agent - OpenAI LLM 未初始化")

# 律師優先使用專用的 OpenAI 實例確保穩定性
if openai_llm_lawyer is not None:
    agents["lawyer"] = Agent(
        config=agents_config["lawyer"],
        llm=openai_llm_lawyer,  # 使用專用的 OpenAI 實例
        verbose=True
    )
    print("✅ Lawyer agent (OpenAI) 創建成功")
elif gemini_llm is not None:
    agents["lawyer"] = Agent(
        config=agents_config["lawyer"],
        llm=gemini_llm,
        verbose=True
    )
    print("✅ Lawyer agent (Gemini) 創建成功")
else:
    print("❌ 無法創建 Lawyer agent - 所有 LLM 都未初始化")

# ---------- 建立任務流程（用程式定義） ----------
def build_crew(user_question: str):
    # 檢查 agents 是否已建立
    if not agents:
        raise Exception("❌ 沒有可用的 agents，請檢查 LLM 初始化")
    
    # 檢查兩個 agent 是否都可用
    if "accountant" not in agents or "lawyer" not in agents:
        raise Exception("❌ 需要會計師和律師兩個 agents 才能運作")
    
    # 會計師任務：從財務角度分析
    analyze_task = Task(
        description=f"""
        作為專業會計師，請針對以下問題從財務與稅務角度提供分析：
        
        問題：{user_question}
        
        請提供：
        1. 財務影響分析
        2. 稅務考量
        3. 風險評估
        4. 具體建議
        """,
        expected_output="詳細的財務分析報告，包含稅務建議和風險評估",
        agent=agents["accountant"]
    )

    # 律師任務：從法律角度提供意見
    legal_task = Task(
        description=f"""
        作為專業律師，請針對以下問題從法律角度提供分析：
        
        問題：{user_question}
        
        請提供：
        1. 法律風險評估
        2. 合規要求
        3. 法律結構建議
        4. 整合財務與法律的綜合建議
        """,
        expected_output="完整的法律分析報告，結合財務考量提供綜合建議",
        agent=agents["lawyer"],
        context=[analyze_task]  # 依賴會計師的分析結果
    )

    crew = Crew(
        agents=[agents["accountant"], agents["lawyer"]],
        tasks=[analyze_task, legal_task],
        process=Process.sequential,
        verbose=True
    )
    return crew

# 增加測試執行區塊
if __name__ == "__main__":
    print("\n--- 正在測試 CrewAI 簡化任務 ---")
    try:
        # 使用一個簡短且無爭議的問題來測試
        test_crew = build_crew("測試問題。")
        result = test_crew.kickoff()
        print("\n--- Crew AI 處理結果 ---")
        print(result)
        print("✅ CrewAI 簡化任務測試成功！")
    except Exception as e:
        print(f"❌ CrewAI 簡化任務測試失敗：{e}")
        print("如果這裡仍然是 BadRequestError，問題可能更複雜。")

=== ai_meeting_assistant/src/ai_meeting_assistant/main.py ===
from crew import build_crew
import os

print("🚀 開始 AI 會議助手...")

# 檢查環境變數
openai_key = os.getenv("OPENAI_API_KEY")
google_key = os.getenv("GOOGLE_API_KEY")

if not openai_key:
    print("⚠️  警告：未找到 OPENAI_API_KEY")
if not google_key:
    print("⚠️  警告：未找到 GOOGLE_API_KEY")

user_question = "我打算開一家公司，要選擇有限公司還是獨資？"

try:
    print("📝 建立 Crew...")
    crew = build_crew(user_question)
    
    print("🔄 執行任務...")
    result = crew.kickoff()
    
    print("\n✅ 最終建議輸出：\n")
    print(result)
    
except Exception as e:
    print(f"\n❌ 執行過程中發生錯誤：")
    print(f"錯誤類型：{type(e).__name__}")
    print(f"錯誤訊息：{str(e)}")
    print("\n💡 可能的解決方案：")
    print("1. 檢查 .env 檔案中的 API 金鑰是否正確")
    print("2. 檢查網路連線")
    print("3. 確認 API 金鑰有足夠的額度")


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/__init__.py ===


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/custom_tool.py ===
from crewai.tools import BaseTool
from typing import Type
from pydantic import BaseModel, Field


class MyCustomToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = (
        "Clear description for what this tool is useful for, your agent will need this information to use it."
    )
    args_schema: Type[BaseModel] = MyCustomToolInput

    def _run(self, argument: str) -> str:
        # Implementation goes here
        return "this is an example of a tool output, ignore it and move along."


=== ai_meeting_assistant/src/ai_meeting_assistant/config/agents.yaml ===
accountant:
  role: 會計師
  goal: 提供財務與稅務建議
  backstory: 擁有多年企業財務經驗的專業會計師，專精於稅務規劃與財務分析。

lawyer:
  role: 律師
  goal: 提供法律建議與合規分析
  backstory: 熟悉公司法與商業法律的律師，專注於企業合規與風險管理。


=== ai_meeting_assistant/src/ai_meeting_assistant/config/tasks.yaml ===
analyze_from_accounting:
  description: >
    使用者輸入的問題是：
    {user_question}

    你是一位會計師，請從財務與稅務角度提供建議與風險分析。
  expected_output: >
    詳細建議與說明
  agent: accountant


=== ai_meeting_assistant/src/ai_meeting_assistant/__pycache__/crew.cpython-311.pyc ===


=== ai_meeting_assistant/src/ai_meeting_assistant/__pycache__/crew.cpython-311.pyc ===
[無法讀取此檔案: 'utf-8' codec can't decode byte 0xa7 in position 0: invalid start byte]
