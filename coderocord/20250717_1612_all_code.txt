

=== ai_meeting_assistant/pyproject.toml ===
[project]
name = "ai_meeting_assistant"
version = "0.1.0"
description = "ai_meeting_assistant using crewAI"
authors = [{ name = "Your Name", email = "you@example.com" }]
requires-python = ">=3.10,<3.14"
dependencies = [
    "crewai[tools]>=0.140.0,<1.0.0",
    "langchain-openai>=0.1.0",
    "langchain-google-genai>=1.0.0",
    "python-dotenv>=1.0.0",
    "pyyaml>=6.0.0"
]

[project.scripts]
ai_meeting_assistant = "ai_meeting_assistant.main:run"
run_crew = "ai_meeting_assistant.main:run"
train = "ai_meeting_assistant.main:train"
replay = "ai_meeting_assistant.main:replay"
test = "ai_meeting_assistant.main:test"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.crewai]
type = "crew"


=== ai_meeting_assistant/README.md ===
# AiMeetingAssistant Crew

Welcome to the AiMeetingAssistant Crew project, powered by [crewAI](https://crewai.com). This template is designed to help you set up a multi-agent AI system with ease, leveraging the powerful and flexible framework provided by crewAI. Our goal is to enable your agents to collaborate effectively on complex tasks, maximizing their collective intelligence and capabilities.

## Installation

Ensure you have Python >=3.10 <3.14 installed on your system. This project uses [UV](https://docs.astral.sh/uv/) for dependency management and package handling, offering a seamless setup and execution experience.

First, if you haven't already, install uv:

```bash
pip install uv
```

Next, navigate to your project directory and install the dependencies:

(Optional) Lock the dependencies and install them by using the CLI command:
```bash
crewai install
```
### Customizing

**Add your `OPENAI_API_KEY` into the `.env` file**

- Modify `src/ai_meeting_assistant/config/agents.yaml` to define your agents
- Modify `src/ai_meeting_assistant/config/tasks.yaml` to define your tasks
- Modify `src/ai_meeting_assistant/crew.py` to add your own logic, tools and specific args
- Modify `src/ai_meeting_assistant/main.py` to add custom inputs for your agents and tasks

## Running the Project

To kickstart your crew of AI agents and begin task execution, run this from the root folder of your project:

```bash
$ crewai run
```

This command initializes the ai_meeting_assistant Crew, assembling the agents and assigning them tasks as defined in your configuration.

This example, unmodified, will run the create a `report.md` file with the output of a research on LLMs in the root folder.

## Understanding Your Crew

The ai_meeting_assistant Crew is composed of multiple AI agents, each with unique roles, goals, and tools. These agents collaborate on a series of tasks, defined in `config/tasks.yaml`, leveraging their collective skills to achieve complex objectives. The `config/agents.yaml` file outlines the capabilities and configurations of each agent in your crew.

## Support

For support, questions, or feedback regarding the AiMeetingAssistant Crew or crewAI.
- Visit our [documentation](https://docs.crewai.com)
- Reach out to us through our [GitHub repository](https://github.com/joaomdmoura/crewai)
- [Join our Discord](https://discord.com/invite/X4JWnZnxPb)
- [Chat with our docs](https://chatg.pt/DWjSBZn)

Let's create wonders together with the power and simplicity of crewAI.


=== ai_meeting_assistant/.gitignore ===
.env
__pycache__/
.DS_Store


=== ai_meeting_assistant/.env ===
MODEL=gpt-4o
OPENAI_API_KEY=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
GOOGLE_API_KEY=AIzaSyDZDDvhc5-iRdv_vNdM9_1fAmvKDVBoRVY
SERPER_API_KEY=673e7b9ba21c606af2d261fd44a5d269057a0a5a


=== ai_meeting_assistant/all_code.py ===
import os
import datetime

# è¨­å®šæ ¹ç›®éŒ„ï¼ˆä½ è¦è¼¸å‡ºçš„è³‡æ–™å¤¾ï¼‰
root_folder = './'  # â† è«‹æ”¹æˆä½ è‡ªå·±çš„è³‡æ–™å¤¾è·¯å¾‘
output_file = 'all_code.txt'
output_file = f"{datetime.datetime.now().strftime('%Y%m%d_%H%M')}_{output_file}"

# è¨­å®šè¼¸å‡ºè³‡æ–™å¤¾
output_folder = './coderocord/'
os.makedirs(output_folder, exist_ok=True)
output_file = os.path.join(output_folder, output_file)

def prompt_user(path):
    rel_path = os.path.relpath(path, root_folder)
    while True:
        choice = input(f"æ˜¯å¦è¦è¼¸å‡º '{rel_path}' çš„å…§å®¹ï¼Ÿ(Y/N): ").strip().upper()
        if choice in ['Y', 'N']:
            return choice == 'Y'
        print("è«‹è¼¸å…¥ Y æˆ– Nã€‚")

with open(output_file, 'w', encoding='utf-8') as out:
    for name in os.listdir(root_folder):
        full_path = os.path.join(root_folder, name)

        if prompt_user(full_path):
            if os.path.isfile(full_path):
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        out.write(f"\n\n=== {name} ===\n")
                        out.write(f.read())
                except Exception as e:
                    out.write(f"\n\n=== {name} ===\n")
                    out.write(f"[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: {e}]\n")

            elif os.path.isdir(full_path):
                for foldername, _, filenames in os.walk(full_path):
                    for filename in filenames:
                        file_path = os.path.join(foldername, filename)
                        rel = os.path.relpath(file_path, root_folder)
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                out.write(f"\n\n=== {rel} ===\n")
                                out.write(f.read())
                        except Exception as e:
                            out.write(f"\n\n=== {rel} ===\n")
                            out.write(f"[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: {e}]\n")

print(f"\nâœ… è¼¸å‡ºå®Œæˆï¼Œè«‹æŸ¥çœ‹ {output_file}")


=== ai_meeting_assistant/saved_chats/é€ƒæ¼ç¨…å›‰.json ===
{
  "meeting_name": "é€ƒæ¼ç¨…å›‰",
  "chat_history": [
    {
      "user": "æˆ‘è©²æ€Žéº¼é¿å…é€ƒæ¼ç¨…ç™¼ç”Ÿï¼Ÿ",
      "agent": "user",
      "reply": ""
    },
    {
      "user": "æˆ‘è©²æ€Žéº¼é¿å…é€ƒæ¼ç¨…ç™¼ç”Ÿï¼Ÿ",
      "agent": "æœƒè¨ˆå¸«",
      "reply": "é¿å…é€ƒæ¼ç¨…çš„ç™¼ç”Ÿéœ€è¦å¾žå¤šå€‹æ–¹é¢è‘—æ‰‹ã€‚é¦–å…ˆï¼Œç¢ºä¿æ‰€æœ‰çš„æ”¶å…¥å’Œæ”¯å‡ºéƒ½è¢«æ­£ç¢ºåœ°è¨˜éŒ„å’Œå ±å‘Šã€‚é€™æ„å‘³è‘—éœ€è¦ä¿æŒè‰¯å¥½çš„æœƒè¨ˆç´€éŒ„ï¼Œä¸¦å®šæœŸå¯©æ ¸é€™äº›ç´€éŒ„ä»¥ç¢ºä¿å…¶æº–ç¢ºæ€§ã€‚å…¶æ¬¡ï¼Œäº†è§£ä¸¦éµå®ˆç•¶åœ°çš„ç¨…å‹™æ³•è¦æ˜¯è‡³é—œé‡è¦çš„ï¼Œé€™æ¨£å¯ä»¥é¿å…å› ä¸ç†Ÿæ‚‰æ³•å¾‹è€Œç„¡æ„ä¸­é•åè¦å®šã€‚ç¬¬ä¸‰ï¼Œè€ƒæ…®è˜è«‹å°ˆæ¥­çš„æœƒè¨ˆå¸«æˆ–ç¨…å‹™é¡§å•ï¼Œä»–å€‘å¯ä»¥æä¾›å°ˆæ¥­çš„å»ºè­°å’ŒæŒ‡å°Žï¼Œå¹«åŠ©ç¢ºä¿æ‰€æœ‰çš„ç¨…å‹™ç”³å ±éƒ½ç¬¦åˆè¦å®šã€‚æ­¤å¤–ï¼Œå®šæœŸåƒåŠ ç¨…å‹™åŸ¹è¨“æˆ–ç ”è¨Žæœƒä»¥æ›´æ–°è‡ªå·±çš„ç¨…å‹™çŸ¥è­˜ä¹Ÿæ˜¯ä¸€å€‹ä¸éŒ¯çš„åšæ³•ã€‚æœ€å¾Œï¼Œèª å¯¦å’Œé€æ˜Žæ˜¯é¿å…é€ƒæ¼ç¨…çš„é—œéµï¼Œç¢ºä¿æ‰€æœ‰çš„è²¡å‹™æ´»å‹•éƒ½æ˜¯åˆæ³•å’Œåˆè¦çš„ã€‚```"
    },
    {
      "user": "ä½ çš„æƒ³æ³•æ˜¯ä»€éº¼ï¼Ÿ",
      "agent": "user",
      "reply": ""
    },
    {
      "user": "ä½ çš„æƒ³æ³•æ˜¯ä»€éº¼ï¼Ÿ",
      "agent": "å¾‹å¸«",
      "reply": "ä½œç‚ºå¾‹å¸«ï¼Œæˆ‘åŒæ„æœƒè¨ˆå¸«æä¾›çš„å»ºè­°ï¼Œä¸¦è£œå……ä¸€äº›æ³•å¾‹å±¤é¢çš„æ„è¦‹ã€‚é¦–å…ˆï¼Œä¼æ¥­æ‡‰åˆ¶å®šä¸¦å¯¦æ–½åš´æ ¼çš„å…§éƒ¨æŽ§åˆ¶åˆ¶åº¦ï¼Œä»¥ç¢ºä¿æ‰€æœ‰è²¡å‹™äº¤æ˜“çš„åˆæ³•æ€§å’Œé€æ˜Žæ€§ã€‚å…¶æ¬¡ï¼Œæ‡‰å®šæœŸé€²è¡Œå…§éƒ¨æˆ–å¤–éƒ¨å¯©è¨ˆï¼Œä»¥è­˜åˆ¥å’Œç³¾æ­£å¯èƒ½çš„åˆè¦å•é¡Œã€‚æ­¤å¤–ï¼Œä¼æ¥­æ‡‰ç¢ºä¿æ‰€æœ‰ç›¸é—œäººå“¡ï¼ŒåŒ…æ‹¬ç®¡ç†å±¤å’Œå“¡å·¥ï¼ŒæŽ¥å—å¿…è¦çš„æ³•å¾‹å’Œç¨…å‹™åŸ¹è¨“ï¼Œä»¥æé«˜ä»–å€‘çš„åˆè¦æ„è­˜å’Œèƒ½åŠ›ã€‚æœ€å¾Œï¼Œä¼æ¥­æ‡‰èˆ‡æ³•å¾‹é¡§å•ä¿æŒå¯†åˆ‡è¯ç¹«ï¼Œä»¥ä¾¿åœ¨é‡åˆ°è¤‡é›œçš„æ³•å¾‹å•é¡Œæ™‚åŠæ™‚ç²å¾—å°ˆæ¥­å»ºè­°ï¼Œç¢ºä¿æ‰€æœ‰è¡Œç‚ºéƒ½ç¬¦åˆæ³•å¾‹è¦å®šã€‚é€™äº›æŽªæ–½å°‡æœ‰åŠ©æ–¼é™ä½Žé€ƒæ¼ç¨…é¢¨éšªï¼Œä¸¦å¢žå¼·ä¼æ¥­çš„æ³•å¾‹åˆè¦æ€§ã€‚"
    }
  ],
  "role1_cfg": {
    "name": "æœƒè¨ˆå¸«",
    "backstory": "æ“æœ‰è±å¯Œç¨…å‹™èˆ‡è²¡å‹™ç®¡ç†ç¶“é©—çš„æœƒè¨ˆå¸«",
    "task": "å¾žè²¡å‹™èˆ‡ç¨…å‹™è§’åº¦æä¾›å»ºè­°"
  },
  "role2_cfg": {
    "name": "å¾‹å¸«",
    "backstory": "ç†Ÿæ‚‰å•†æ¥­åˆè¦èˆ‡å…¬å¸æ³•çš„å¾‹å¸«",
    "task": "å¾žæ³•å¾‹è§’åº¦åˆ†æžå•é¡Œä¸¦æä¾›å»ºè­°"
  }
}

=== ai_meeting_assistant/saved_chats/å°å­¸æ•™å®¤.json ===
{
  "meeting_name": "å°å­¸æ•™å®¤",
  "chat_history": [
    {
      "user": "å‡ºä¸€é¡Œæ•¸å­¸é¡Œç›®",
      "agent": "user",
      "reply": ""
    },
    {
      "user": "å‡ºä¸€é¡Œæ•¸å­¸é¡Œç›®",
      "agent": "è€å¸«",
      "reply": "å¥½çš„ï¼Œé€™æ˜¯ä¸€é“æ•¸å­¸é¡Œç›®çµ¦ä½ ç·´ç¿’ï¼šå¦‚æžœä¸€å€‹ç±ƒå­è£¡æœ‰15å€‹è˜‹æžœï¼Œç„¶å¾Œä½ åˆæ”¾é€²åŽ»7å€‹è˜‹æžœï¼Œæœ€å¾Œæ‹¿èµ°4å€‹è˜‹æžœï¼Œç±ƒå­è£¡é‚„å‰©ä¸‹å¤šå°‘å€‹è˜‹æžœå‘¢ï¼Ÿè«‹è©¦è‘—è¨ˆç®—ä¸€ä¸‹ï¼Œç„¶å¾Œå‘Šè¨´æˆ‘ä½ çš„ç­”æ¡ˆã€‚"
    },
    {
      "user": "è«‹å›žç­”",
      "agent": "user",
      "reply": ""
    },
    {
      "user": "è«‹å›žç­”",
      "agent": "å­¸ç”Ÿ",
      "reply": "é€™æ˜¯ä¸€é“æ•¸å­¸é¡Œç›®ï¼Œè®“æˆ‘å€‘ä¸€èµ·ä¾†è§£ç­”å§ã€‚æ ¹æ“šé¡Œç›®ï¼Œå¦‚æžœç±ƒå­è£¡åŽŸæœ¬æœ‰15å€‹è˜‹æžœï¼Œç„¶å¾Œä½ åˆæ”¾é€²åŽ»7å€‹è˜‹æžœï¼Œé€™æ™‚ç±ƒå­è£¡æœ‰15 + 7 = 22å€‹è˜‹æžœã€‚æŽ¥è‘—ï¼Œä½ æ‹¿èµ°4å€‹è˜‹æžœï¼Œæ‰€ä»¥ç±ƒå­è£¡å‰©ä¸‹22 - 4 = 18å€‹è˜‹æžœã€‚å› æ­¤ï¼Œç±ƒå­è£¡é‚„å‰©ä¸‹18å€‹è˜‹æžœã€‚"
    },
    {
      "user": "ç­”æ¡ˆæ­£ç¢ºå—Žï¼Ÿ",
      "agent": "user",
      "reply": ""
    },
    {
      "user": "ç­”æ¡ˆæ­£ç¢ºå—Žï¼Ÿ",
      "agent": "è€å¸«",
      "reply": "ç­”æ¡ˆæ­£ç¢ºï¼ç±ƒå­è£¡æœ€çµ‚å‰©ä¸‹18å€‹è˜‹æžœã€‚ä½ è¨ˆç®—å¾—å¾ˆå¥½ï¼Œç¹¼çºŒä¿æŒé€™ç¨®å­¸ç¿’æ…‹åº¦ï¼å¦‚æžœé‚„æœ‰å…¶ä»–å•é¡Œæˆ–éœ€è¦æ›´å¤šç·´ç¿’é¡Œï¼Œéš¨æ™‚å‘Šè¨´æˆ‘ã€‚"
    }
  ],
  "role1_cfg": {
    "name": "è€å¸«",
    "backstory": "ç¶“é©—è±å¯Œçš„æ•¸å­¸è€å¸«",
    "task": "å‡ºé¡Œç›®çµ¦å°å­¸ç”Ÿç·´ç¿’ï¼Œä¸è¦æä¾›è§£ç­”ï¼Œå­¸ç”Ÿå›žç­”å¾Œç¢ºèªæ˜¯å¦æ­£ç¢º"
  },
  "role2_cfg": {
    "name": "å­¸ç”Ÿ",
    "backstory": "å‰›è®€å°å­¸çš„å­¸ç”Ÿ",
    "task": "æ€è€ƒå¾Œå›žç­”å•é¡Œ"
  }
}

=== ai_meeting_assistant/knowledge/user_preference.txt ===


=== ai_meeting_assistant/src/.DS_Store ===


=== ai_meeting_assistant/src/.DS_Store ===
[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: 'utf-8' codec can't decode byte 0x86 in position 23: invalid start byte]


=== ai_meeting_assistant/src/ai_meeting_assistant/.DS_Store ===


=== ai_meeting_assistant/src/ai_meeting_assistant/.DS_Store ===
[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte]


=== ai_meeting_assistant/src/ai_meeting_assistant/__init__.py ===


=== ai_meeting_assistant/src/ai_meeting_assistant/crew.py ===
import os
import yaml
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from crewai import Agent, Task, Crew, Process

# è®€å–ç’°å¢ƒè®Šæ•¸
load_dotenv()

# ---------- è®€å– YAML ----------
def load_yaml_config(path):
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

this_dir = os.path.dirname(__file__)
agents_config = load_yaml_config(os.path.join(this_dir, "config/agents.yaml"))

# ---------- å»ºç«‹ LLM ----------
try:
    openai_llm = ChatOpenAI(
        model="gpt-4o",  # ä½¿ç”¨ .env ä¸­å®šç¾©çš„æ¨¡åž‹
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    print("âœ… OpenAI LLM åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ OpenAI LLM åˆå§‹åŒ–å¤±æ•—: {e}")
    openai_llm = None

# ç‚ºäº†ç©©å®šæ€§ï¼Œæš«æ™‚å…©å€‹ agent éƒ½ä½¿ç”¨ OpenAI
try:
    openai_llm_lawyer = ChatOpenAI(
        model="gpt-4o",  # ä½¿ç”¨ç›¸åŒçš„æ¨¡åž‹ä½†ä¸åŒçš„å¯¦ä¾‹
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    print("âœ… Lawyer OpenAI LLM åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Lawyer OpenAI LLM åˆå§‹åŒ–å¤±æ•—: {e}")
    openai_llm_lawyer = None

# Gemini LLM æš«æ™‚ä½œç‚ºå‚™ç”¨
try:
    gemini_llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",  # ç°¡åŒ–æ¨¡åž‹åç¨±
        temperature=0.3,
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    print("âœ… Gemini LLM åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Gemini LLM åˆå§‹åŒ–å¤±æ•—: {e}")
    gemini_llm = None

# ---------- å»ºç«‹ Agents ----------
agents = {}

# æœƒè¨ˆå¸«ä½¿ç”¨ OpenAI
if openai_llm is not None:
    accountant_cfg = agents_config["accountant"]
    agents["accountant"] = Agent(
        role=accountant_cfg["role"],
        goal=accountant_cfg["goal"],
        backstory=accountant_cfg["backstory"],
        llm=openai_llm,
        verbose=True
    )
    print("âœ… Accountant agent å‰µå»ºæˆåŠŸ")
else:
    print("âŒ ç„¡æ³•å‰µå»º Accountant agent - OpenAI LLM æœªåˆå§‹åŒ–")

# å¾‹å¸«å„ªå…ˆä½¿ç”¨å°ˆç”¨çš„ OpenAI å¯¦ä¾‹ç¢ºä¿ç©©å®šæ€§
lawyer_cfg = agents_config["lawyer"]
if openai_llm_lawyer is not None:
    agents["lawyer"] = Agent(
        role=lawyer_cfg["role"],
        goal=lawyer_cfg["goal"],
        backstory=lawyer_cfg["backstory"],
        llm=openai_llm_lawyer,  # ä½¿ç”¨å°ˆç”¨çš„ OpenAI å¯¦ä¾‹
        verbose=True
    )
    print("âœ… Lawyer agent (OpenAI) å‰µå»ºæˆåŠŸ")
elif gemini_llm is not None:
    agents["lawyer"] = Agent(
        role=lawyer_cfg["role"],
        goal=lawyer_cfg["goal"],
        backstory=lawyer_cfg["backstory"],
        llm=gemini_llm,
        verbose=True
    )
    print("âœ… Lawyer agent (Gemini) å‰µå»ºæˆåŠŸ")
else:
    print("âŒ ç„¡æ³•å‰µå»º Lawyer agent - æ‰€æœ‰ LLM éƒ½æœªåˆå§‹åŒ–")

# ---------- å»ºç«‹ä»»å‹™æµç¨‹ï¼ˆç”¨ç¨‹å¼å®šç¾©ï¼‰ ----------
def build_crew(user_question: str, accountant_backstory=None, accountant_task=None,
               lawyer_backstory=None, lawyer_task=None):
    if not agents or "accountant" not in agents or "lawyer" not in agents:
        raise Exception("âŒ å¿…é ˆæœ‰æœƒè¨ˆå¸«å’Œå¾‹å¸« agents")

    # å¦‚æžœä½¿ç”¨è€…è‡ªè¨‚äº† backstoryï¼Œå‹•æ…‹æ›´æ–°
    if accountant_backstory:
        agents["accountant"].config.backstory = accountant_backstory
    if lawyer_backstory:
        agents["lawyer"].config.backstory = lawyer_backstory

    # å‹•æ…‹ä»»å‹™èªªæ˜Ž
    analyze_task = Task(
        description=f"{accountant_task or 'è«‹å¾žè²¡å‹™èˆ‡ç¨…å‹™è§’åº¦æä¾›å»ºè­°èˆ‡é¢¨éšªåˆ†æžã€‚'}\n\nå•é¡Œï¼š{user_question}",
        expected_output="è©³ç´°çš„è²¡å‹™åˆ†æžå ±å‘Šï¼ŒåŒ…å«ç¨…å‹™å»ºè­°å’Œé¢¨éšªè©•ä¼°",
        agent=agents["accountant"]
    )

    legal_task = Task(
        description=f"{lawyer_task or 'è«‹å¾žæ³•å¾‹è§’åº¦æä¾›å»ºè­°èˆ‡åˆè¦åˆ†æžï¼Œä¸¦çµåˆè²¡å‹™è€ƒé‡ã€‚'}\n\nå•é¡Œï¼š{user_question}",
        expected_output="å®Œæ•´çš„æ³•å¾‹åˆ†æžå ±å‘Šï¼Œçµåˆè²¡å‹™è€ƒé‡æä¾›ç¶œåˆå»ºè­°",
        agent=agents["lawyer"],
        context=[analyze_task]
    )

    crew = Crew(
        agents=[agents["accountant"], agents["lawyer"]],
        tasks=[analyze_task, legal_task],
        process=Process.sequential,
        verbose=True
    )
    return crew, analyze_task, legal_task

from crewai import Agent

def build_custom_crew(user_question: str, role1: dict, role2: dict):
    # LLM åˆå§‹åŒ–ï¼ˆä½ å·²æœ‰ openai_llmï¼‰
    agent1 = Agent(
        role=role1["name"],
        goal=role1["task"],
        backstory=role1["backstory"],
        llm=openai_llm,
        verbose=True
    )
    agent2 = Agent(
        role=role2["name"],
        goal=role2["task"],
        backstory=role2["backstory"],
        llm=openai_llm_lawyer or openai_llm,
        verbose=True
    )

    task1 = Task(
        description=f"{role1['task']}\n\nå•é¡Œï¼š{user_question}",
        expected_output="å®Œæ•´åˆ†æžå»ºè­°",
        agent=agent1
    )

    task2 = Task(
        description=f"{role2['task']}\n\nå•é¡Œï¼š{user_question}",
        expected_output="çµåˆç¬¬ä¸€ä½è§’è‰²æ„è¦‹çš„åˆ†æžèˆ‡å»ºè­°",
        agent=agent2,
        context=[task1]
    )

    crew = Crew(
        agents=[agent1, agent2],
        tasks=[task1, task2],
        process=Process.sequential,
        verbose=True
    )

    return crew, task1, task2

def build_memory_agent_task(
    user_question: str,
    role_name: str,
    backstory: str,
    task_instruction: str,
    history_log: list,
    llm_instance
):
    from crewai import Agent, Task, Crew

    # æ•´ç†ä¸Šä¸‹æ–‡æ­·å²
    history = ""
    for entry in history_log:
        history += f"- ä½¿ç”¨è€…ï¼š{entry['user']}\n"
        history += f"  {entry['agent']} å›žè¦†ï¼š{entry['reply']}\n"

    # å»ºç«‹ Agent
    agent = Agent(
        role=role_name,
        goal=task_instruction,
        backstory=backstory,
        llm=llm_instance,
        verbose=True
    )

    # å»ºç«‹ä»»å‹™
    task = Task(
        description=f"""ä½ æ˜¯ {role_name}ï¼Œè«‹æ ¹æ“šä»¥ä¸‹æ­·å²å°è©±èˆ‡ä½¿ç”¨è€…çš„æ–°å•é¡Œé€²è¡Œå›žè¦†ï¼š

{history}

ðŸ”Ž ä½¿ç”¨è€…çš„æ–°æå•ï¼š
{user_question}
""",
        expected_output="è«‹æä¾›å°ˆæ¥­ä¸”æœ‰ä¸Šä¸‹æ–‡é€£è²«çš„å›žæ‡‰å»ºè­°",
        agent=agent
    )

    crew = Crew(
        agents=[agent],
        tasks=[task],
        process=Process.sequential,
        verbose=True
    )

    return crew, task


# å¢žåŠ æ¸¬è©¦åŸ·è¡Œå€å¡Š
if __name__ == "__main__":
    print("\n--- æ­£åœ¨æ¸¬è©¦ CrewAI ç°¡åŒ–ä»»å‹™ ---")
    try:
        # ä½¿ç”¨ä¸€å€‹ç°¡çŸ­ä¸”ç„¡çˆ­è­°çš„å•é¡Œä¾†æ¸¬è©¦
        test_crew = build_crew("æ¸¬è©¦å•é¡Œã€‚")
        result = test_crew.kickoff()
        print("\n--- Crew AI è™•ç†çµæžœ ---")
        print(result)
        print("âœ… CrewAI ç°¡åŒ–ä»»å‹™æ¸¬è©¦æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ CrewAI ç°¡åŒ–ä»»å‹™æ¸¬è©¦å¤±æ•—ï¼š{e}")
        print("å¦‚æžœé€™è£¡ä»ç„¶æ˜¯ BadRequestErrorï¼Œå•é¡Œå¯èƒ½æ›´è¤‡é›œã€‚")

=== ai_meeting_assistant/src/ai_meeting_assistant/app.py ===
import streamlit as st
import os
import json
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
from src.ai_meeting_assistant.crew import build_memory_agent_task, openai_llm

st.set_page_config(page_title="AI è¼ªæ›¿å¼æœƒè­°åŠ©æ‰‹", layout="wide")
st.title("ðŸ§  AI è¼ªæ›¿å¼æœƒè­°åŠ©æ‰‹ï¼ˆå«è§’è‰²èˆ‡ä¸»é¡Œè¨˜æ†¶åŠŸèƒ½ï¼‰")

SAVE_DIR = "./saved_chats"
os.makedirs(SAVE_DIR, exist_ok=True)

# ---------------- åˆå§‹åŒ– ----------------
default_role1 = {
    "name": "æœƒè¨ˆå¸«",
    "backstory": "æ“æœ‰è±å¯Œç¨…å‹™èˆ‡è²¡å‹™ç®¡ç†ç¶“é©—çš„æœƒè¨ˆå¸«",
    "task": "å¾žè²¡å‹™èˆ‡ç¨…å‹™è§’åº¦æä¾›å»ºè­°"
}

default_role2 = {
    "name": "å¾‹å¸«",
    "backstory": "ç†Ÿæ‚‰å•†æ¥­åˆè¦èˆ‡å…¬å¸æ³•çš„å¾‹å¸«",
    "task": "å¾žæ³•å¾‹è§’åº¦åˆ†æžå•é¡Œä¸¦æä¾›å»ºè­°"
}

if "meeting_name" not in st.session_state:
    st.session_state.meeting_name = "æœªå‘½åæœƒè­°"
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "role1_cfg" not in st.session_state:
    st.session_state.role1_cfg = default_role1.copy()
if "role2_cfg" not in st.session_state:
    st.session_state.role2_cfg = default_role2.copy()

# ---------------- å·¥å…·å‡½å¼ ----------------
def get_output_text(output):
    if hasattr(output, "content"):
        return output.content
    elif isinstance(output, str):
        return output
    elif hasattr(output, "result"):
        return output.result
    return str(output)

def save_chat(meeting_name, chat_history):
    data = {
        "meeting_name": meeting_name,
        "chat_history": [],
        "role1_cfg": st.session_state.role1_cfg,
        "role2_cfg": st.session_state.role2_cfg
    }
    for entry in chat_history:
        clean_entry = dict(entry)
        clean_entry["reply"] = get_output_text(clean_entry["reply"])
        data["chat_history"].append(clean_entry)

    path = os.path.join(SAVE_DIR, f"{meeting_name}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_chat(meeting_name):
    path = os.path.join(SAVE_DIR, f"{meeting_name}.json")
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)

    st.session_state.chat_history = data.get("chat_history", [])
    st.session_state.role1_cfg = data.get("role1_cfg", default_role1.copy())
    st.session_state.role2_cfg = data.get("role2_cfg", default_role2.copy())
    st.session_state.meeting_name = data.get("meeting_name", meeting_name)

def list_saved_meetings():
    return [f[:-5] for f in os.listdir(SAVE_DIR) if f.endswith(".json")]

# ---------------- Sidebar æ¨¡å¼é¸æ“‡ ----------------
st.sidebar.header("ðŸ“ é¸æ“‡å°è©±æ¨¡å¼")
mode = st.sidebar.radio("è«‹é¸æ“‡ï¼š", ["ðŸ†• é–‹å•Ÿæ–°æœƒè­°", "ðŸ“‚ è¼‰å…¥éŽåŽ»æœƒè­°"])

if mode == "ðŸ“‚ è¼‰å…¥éŽåŽ»æœƒè­°":
    saved = list_saved_meetings()
    selected = st.sidebar.selectbox("é¸æ“‡éŽåŽ»æœƒè­°ï¼š", saved)
    if st.sidebar.button("ðŸ“¤ è¼‰å…¥"):
        load_chat(selected)
        st.success(f"âœ… å·²è¼‰å…¥æœƒè­°ï¼š{selected}")
else:
    if st.sidebar.button("ðŸ”„ é‡ç½®ç‚ºæ–°æœƒè­°"):
        st.session_state.meeting_name = "æœªå‘½åæœƒè­°"
        st.session_state.chat_history = []
        st.session_state.role1_cfg = default_role1.copy()
        st.session_state.role2_cfg = default_role2.copy()

# ---------------- Header: ä¸»é¡Œèˆ‡å„²å­˜ ----------------
st.markdown("### ðŸ’¼ ç•¶å‰æœƒè­°ä¸»é¡Œ")
st.session_state.meeting_name = st.text_input("ðŸ“ æœƒè­°ä¸»é¡Œ", value=st.session_state.meeting_name)

col_save, _ = st.columns([1, 5])
with col_save:
    if st.button("ðŸ’¾ å„²å­˜ç›®å‰å°è©±", use_container_width=True):
        save_chat(st.session_state.meeting_name, st.session_state.chat_history)
        st.success(f"âœ… å°è©±å·²å„²å­˜ç‚ºï¼šã€Œ{st.session_state.meeting_name}ã€")

# ---------------- è§’è‰²è¨­å®š ----------------
st.subheader("ðŸ‘¥ è‡ªè¨‚å…©ä½è§’è‰²")
col1, col2 = st.columns(2)

with col1:
    st.session_state.role1_cfg["name"] = st.text_input("è§’è‰² 1 åç¨±", value=st.session_state.role1_cfg["name"])
    st.session_state.role1_cfg["backstory"] = st.text_area("è§’è‰² 1 èƒŒæ™¯", value=st.session_state.role1_cfg["backstory"])
    st.session_state.role1_cfg["task"] = st.text_area("è§’è‰² 1 ä»»å‹™", value=st.session_state.role1_cfg["task"])

with col2:
    st.session_state.role2_cfg["name"] = st.text_input("è§’è‰² 2 åç¨±", value=st.session_state.role2_cfg["name"])
    st.session_state.role2_cfg["backstory"] = st.text_area("è§’è‰² 2 èƒŒæ™¯", value=st.session_state.role2_cfg["backstory"])
    st.session_state.role2_cfg["task"] = st.text_area("è§’è‰² 2 ä»»å‹™", value=st.session_state.role2_cfg["task"])

# ---------------- å•é¡Œè¼¸å…¥èˆ‡è§’è‰²æŒ‰éˆ• ----------------
st.subheader("ðŸ’¬ è«‹è¼¸å…¥æ‚¨çš„æœƒè­°å•é¡Œï¼š")
user_input = st.text_input("æ‚¨çš„å•é¡Œï¼š", value="")

col_btn1, col_btn2 = st.columns(2)
selected_role = None
role_cfg = None
run_task = False

if col_btn1.button(f"ðŸ“Š {st.session_state.role1_cfg['name']}å›žè¦†", use_container_width=True) and user_input.strip():
    selected_role = st.session_state.role1_cfg["name"]
    role_cfg = st.session_state.role1_cfg
    run_task = True

if col_btn2.button(f"âš–ï¸ {st.session_state.role2_cfg['name']}å›žè¦†", use_container_width=True) and user_input.strip():
    selected_role = st.session_state.role2_cfg["name"]
    role_cfg = st.session_state.role2_cfg
    run_task = True

# ---------------- åŸ·è¡Œä»»å‹™ ----------------
if run_task and role_cfg:
    st.session_state.chat_history.append({
        "user": user_input,
        "agent": "user",
        "reply": ""
    })

    with st.spinner(f"{selected_role} æ­£åœ¨åˆ†æž..."):
        crew, task = build_memory_agent_task(
            user_question=user_input,
            role_name=role_cfg["name"],
            backstory=role_cfg["backstory"],
            task_instruction=role_cfg["task"],
            history_log=st.session_state.chat_history,
            llm_instance=openai_llm
        )
        result = crew.kickoff()
        reply_text = get_output_text(task.output)
        st.success(f"{selected_role} å›žè¦†ï¼š\n\n{reply_text}")
        st.session_state.chat_history.append({
            "user": user_input,
            "agent": selected_role,
            "reply": reply_text
        })

# ---------------- æ­·å²å°è©± ----------------
st.divider()
st.subheader("ðŸ—‚ï¸ æ­·å²å°è©±")
for entry in st.session_state.chat_history:
    if entry["agent"] != "user":
        st.markdown(f"**ðŸ§‘â€ðŸ’¼ {entry['agent']} å›žè¦†ï¼š**\n\n{entry['reply']}")


=== ai_meeting_assistant/src/ai_meeting_assistant/main.py ===
import os
from crew import build_custom_crew

print("ðŸš€ AI å¤šè§’è‰²æœƒè­°åŠ©æ‰‹ CLI ç‰ˆæœ¬")

# æª¢æŸ¥ API é‡‘é‘°
openai_key = os.getenv("OPENAI_API_KEY")
google_key = os.getenv("GOOGLE_API_KEY")

if not openai_key:
    print("âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ° OPENAI_API_KEY")
if not google_key:
    print("âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ° GOOGLE_API_KEY")

# è‡ªè¨‚å…©ä½è§’è‰²
print("\nðŸ‘¥ è«‹è¨­å®šç¬¬ 1 ä½è§’è‰²ï¼š")
role1_name = input("è§’è‰²åç¨±ï¼ˆé è¨­ï¼šæœƒè¨ˆé¡§å•ï¼‰: ").strip() or "æœƒè¨ˆé¡§å•"
role1_backstory = input("èƒŒæ™¯æè¿°ï¼ˆé è¨­ï¼šæ“…é•·ç¨…å‹™èˆ‡è²¡å‹™åˆ†æžï¼‰: ").strip() or "æ“…é•·ç¨…å‹™èˆ‡è²¡å‹™åˆ†æž"
role1_task = input("ä»»å‹™èªªæ˜Žï¼ˆé è¨­ï¼šå¾žè²¡å‹™è§’åº¦æä¾›å»ºè­°ï¼‰: ").strip() or "å¾žè²¡å‹™è§’åº¦æä¾›å»ºè­°"

print("\nðŸ‘¥ è«‹è¨­å®šç¬¬ 2 ä½è§’è‰²ï¼š")
role2_name = input("è§’è‰²åç¨±ï¼ˆé è¨­ï¼šæ³•å¾‹é¡§å•ï¼‰: ").strip() or "æ³•å¾‹é¡§å•"
role2_backstory = input("èƒŒæ™¯æè¿°ï¼ˆé è¨­ï¼šæ“…é•·å…¬å¸æ³•èˆ‡åˆè¦åˆ†æžï¼‰: ").strip() or "æ“…é•·å…¬å¸æ³•èˆ‡åˆè¦åˆ†æž"
role2_task = input("ä»»å‹™èªªæ˜Žï¼ˆé è¨­ï¼šå¾žæ³•å¾‹è§’åº¦æä¾›å»ºè­°ï¼‰: ").strip() or "å¾žæ³•å¾‹è§’åº¦æä¾›å»ºè­°"

# å•Ÿå‹•äº’å‹•æ¨¡å¼
conversation_history = []

while True:
    print("\nðŸ’¬ è«‹è¼¸å…¥æ‚¨çš„æœƒè­°å•é¡Œï¼ˆè¼¸å…¥ exit çµæŸï¼‰ï¼š")
    user_question = input("> ").strip()

    if user_question.lower() == "exit":
        print("\nðŸ‘‹ æ„Ÿè¬ä½¿ç”¨ AI åŠ©æ‰‹ï¼")
        break

    if not user_question:
        print("âš ï¸  è«‹è¼¸å…¥éžç©ºç™½çš„å•é¡Œã€‚")
        continue

    try:
        print("ðŸ§  å»ºç«‹å¤šè§’è‰²åˆ†æžä»»å‹™...")
        crew, task1, task2 = build_custom_crew(
            user_question=user_question,
            role1={
                "name": role1_name,
                "backstory": role1_backstory,
                "task": role1_task
            },
            role2={
                "name": role2_name,
                "backstory": role2_backstory,
                "task": role2_task
            }
        )

        print("ðŸ” åˆ†æžä¸­ï¼Œè«‹ç¨å€™...\n")
        result = crew.kickoff()

        # å„²å­˜ç´€éŒ„
        conversation_history.append({
            "question": user_question,
            "reply1": task1.output,
            "reply2": task2.output
        })

        print(f"ðŸ§‘â€ðŸ’¼ {role1_name} å›žè¦†ï¼š\n{task1.output}\n")
        print(f"ðŸ§‘â€ðŸ’¼ {role2_name} å›žè¦†ï¼š\n{task2.output}\n")

        # ç¸½çµç´€éŒ„
        print("ðŸ“œ å°è©±ç´€éŒ„ï¼š")
        for idx, conv in enumerate(conversation_history, 1):
            print(f"{idx}. å•é¡Œï¼š{conv['question']}")
            print(f"   {role1_name}ï¼š{conv['reply1'][:60]}...")
            print(f"   {role2_name}ï¼š{conv['reply2'][:60]}...\n")

    except Exception as e:
        print("\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š")
        print(f"éŒ¯èª¤é¡žåž‹ï¼š{type(e).__name__}")
        print(f"éŒ¯èª¤è¨Šæ¯ï¼š{e}")
        print("ðŸ’¡ æª¢æŸ¥ API é‡‘é‘°èˆ‡é€£ç·šç‹€æ…‹")


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/__init__.py ===


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/web_search_tool.py ===
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field
from typing import ClassVar
from langchain_community.utilities import GoogleSerperAPIWrapper

class WebSearchInput(BaseModel):
    query: str = Field(..., description="ç”¨æ–¼æŸ¥è©¢çš„é—œéµå­—")

class WebSearchTool(BaseTool):
    args_schema: ClassVar[type] = WebSearchInput

    def __init__(self):
        super().__init__(
            name="Web Search",
            description="ä½¿ç”¨ Serper API åŸ·è¡Œå³æ™‚ç¶²è·¯æœå°‹"
        )

    def _run(self, query: str) -> str:
        try:
            search = GoogleSerperAPIWrapper()
            return search.run(query)
        except Exception as e:
            return f"æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/custom_tool.py ===
from crewai.tools import BaseTool
from typing import Type
from pydantic import BaseModel, Field


class MyCustomToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = (
        "Clear description for what this tool is useful for, your agent will need this information to use it."
    )
    args_schema: Type[BaseModel] = MyCustomToolInput

    def _run(self, argument: str) -> str:
        # Implementation goes here
        return "this is an example of a tool output, ignore it and move along."


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/__pycache__/web_search_tool.cpython-311.pyc ===


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/__pycache__/web_search_tool.cpython-311.pyc ===
[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: 'utf-8' codec can't decode byte 0xa7 in position 0: invalid start byte]


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/__pycache__/__init__.cpython-311.pyc ===


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/__pycache__/__init__.cpython-311.pyc ===
[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: 'utf-8' codec can't decode byte 0xa7 in position 0: invalid start byte]


=== ai_meeting_assistant/src/ai_meeting_assistant/config/agents.yaml ===
accountant:
  role: æœƒè¨ˆå¸«
  goal: æä¾›è²¡å‹™èˆ‡ç¨…å‹™å»ºè­°
  backstory: æ“æœ‰å¤šå¹´ä¼æ¥­è²¡å‹™ç¶“é©—çš„å°ˆæ¥­æœƒè¨ˆå¸«ï¼Œå°ˆç²¾æ–¼ç¨…å‹™è¦åŠƒèˆ‡è²¡å‹™åˆ†æžã€‚

lawyer:
  role: å¾‹å¸«
  goal: æä¾›æ³•å¾‹å»ºè­°èˆ‡åˆè¦åˆ†æž
  backstory: ç†Ÿæ‚‰å…¬å¸æ³•èˆ‡å•†æ¥­æ³•å¾‹çš„å¾‹å¸«ï¼Œå°ˆæ³¨æ–¼ä¼æ¥­åˆè¦èˆ‡é¢¨éšªç®¡ç†ã€‚


=== ai_meeting_assistant/src/ai_meeting_assistant/config/tasks.yaml ===
analyze_from_accounting:
  description: >
    ä½¿ç”¨è€…è¼¸å…¥çš„å•é¡Œæ˜¯ï¼š
    {user_question}

    ä½ æ˜¯ä¸€ä½æœƒè¨ˆå¸«ï¼Œè«‹å¾žè²¡å‹™èˆ‡ç¨…å‹™è§’åº¦æä¾›å»ºè­°èˆ‡é¢¨éšªåˆ†æžã€‚
  expected_output: >
    è©³ç´°å»ºè­°èˆ‡èªªæ˜Ž
  agent: accountant

