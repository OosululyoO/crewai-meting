

=== ai_meeting_assistant/pyproject.toml ===
[project]
name = "ai_meeting_assistant"
version = "0.1.0"
description = "ai_meeting_assistant using crewAI"
authors = [{ name = "Your Name", email = "you@example.com" }]
requires-python = ">=3.10,<3.14"
dependencies = [
    "crewai[tools]>=0.140.0,<1.0.0",
    "langchain-openai>=0.1.0",
    "langchain-google-genai>=1.0.0",
    "python-dotenv>=1.0.0",
    "pyyaml>=6.0.0"
]

[project.scripts]
ai_meeting_assistant = "ai_meeting_assistant.main:run"
run_crew = "ai_meeting_assistant.main:run"
train = "ai_meeting_assistant.main:train"
replay = "ai_meeting_assistant.main:replay"
test = "ai_meeting_assistant.main:test"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.crewai]
type = "crew"


=== ai_meeting_assistant/README.md ===
# AiMeetingAssistant Crew

Welcome to the AiMeetingAssistant Crew project, powered by [crewAI](https://crewai.com). This template is designed to help you set up a multi-agent AI system with ease, leveraging the powerful and flexible framework provided by crewAI. Our goal is to enable your agents to collaborate effectively on complex tasks, maximizing their collective intelligence and capabilities.

## Installation

Ensure you have Python >=3.10 <3.14 installed on your system. This project uses [UV](https://docs.astral.sh/uv/) for dependency management and package handling, offering a seamless setup and execution experience.

First, if you haven't already, install uv:

```bash
pip install uv
```

Next, navigate to your project directory and install the dependencies:

(Optional) Lock the dependencies and install them by using the CLI command:
```bash
crewai install
```
### Customizing

**Add your `OPENAI_API_KEY` into the `.env` file**

- Modify `src/ai_meeting_assistant/config/agents.yaml` to define your agents
- Modify `src/ai_meeting_assistant/config/tasks.yaml` to define your tasks
- Modify `src/ai_meeting_assistant/crew.py` to add your own logic, tools and specific args
- Modify `src/ai_meeting_assistant/main.py` to add custom inputs for your agents and tasks

## Running the Project

To kickstart your crew of AI agents and begin task execution, run this from the root folder of your project:

```bash
$ crewai run
```

This command initializes the ai_meeting_assistant Crew, assembling the agents and assigning them tasks as defined in your configuration.

This example, unmodified, will run the create a `report.md` file with the output of a research on LLMs in the root folder.

## Understanding Your Crew

The ai_meeting_assistant Crew is composed of multiple AI agents, each with unique roles, goals, and tools. These agents collaborate on a series of tasks, defined in `config/tasks.yaml`, leveraging their collective skills to achieve complex objectives. The `config/agents.yaml` file outlines the capabilities and configurations of each agent in your crew.

## Support

For support, questions, or feedback regarding the AiMeetingAssistant Crew or crewAI.
- Visit our [documentation](https://docs.crewai.com)
- Reach out to us through our [GitHub repository](https://github.com/joaomdmoura/crewai)
- [Join our Discord](https://discord.com/invite/X4JWnZnxPb)
- [Chat with our docs](https://chatg.pt/DWjSBZn)

Let's create wonders together with the power and simplicity of crewAI.


=== ai_meeting_assistant/testgemini.py ===
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
import google.generativeai as genai # ç”¨æ–¼ ListModels æª¢æŸ¥

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# å†æ¬¡ç¢ºèª API Key æ˜¯å¦æˆåŠŸè¼‰å…¥
print(f"API Key: {'å·²è¼‰å…¥' if api_key else 'æœªè¼‰å…¥'}")

# è¨­å®š Gemini API Key (å° ChatGoogleGenerativeAI ä¹Ÿæœ‰å¹«åŠ©ï¼Œç¢ºä¿åº•å±¤é…ç½®æ­£ç¢º)
genai.configure(api_key=api_key)

print("\n--- æª¢æŸ¥å¯ç”¨çš„ Gemini æ¨¡å‹ ---")
found_target_model = False
target_model_name = "models/gemini-1.5-pro" # ä½ æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹
for m in genai.list_models():
    if m.name == target_model_name and "generateContent" in m.supported_generation_methods:
        print(f"âœ… æ¨¡å‹ {target_model_name} å·²æ‰¾åˆ°ä¸¦æ”¯æ´ generateContentã€‚")
        found_target_model = True
        break
    elif m.name == target_model_name:
        print(f"âŒ æ¨¡å‹ {target_model_name} å·²æ‰¾åˆ°ï¼Œä½†**ä¸æ”¯æ´** generateContentã€‚")
        print(f"æ”¯æ´æ–¹æ³•ï¼š{m.supported_generation_methods}")
        found_target_model = True
        break

if not found_target_model:
    print(f"âŒ æ¨¡å‹ {target_model_name} åœ¨æ‚¨çš„ API æ¬Šé™ä¸‹æœªæ‰¾åˆ°ã€‚")
    print("è«‹ç¢ºèªæ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢ºï¼Œæˆ–æª¢æŸ¥å€åŸŸå¯ç”¨æ€§ã€‚")

print("-----------------------------\n")


# ç¨ç«‹æ¸¬è©¦ ChatGoogleGenerativeAI
if found_target_model:
    try:
        print("--- ç¨ç«‹æ¸¬è©¦ ChatGoogleGenerativeAI ---")
        gemini_llm_test = ChatGoogleGenerativeAI(
            model=target_model_name,
            temperature=0.3
        )
        test_message = "è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹ä½ è‡ªå·±ã€‚"
        response = gemini_llm_test.invoke(test_message) # ä½¿ç”¨ invoke æ–¹æ³•
        print("âœ… ChatGoogleGenerativeAI ç¨ç«‹æ¸¬è©¦æˆåŠŸï¼")
        print("å›æ‡‰:", response.content)
        print("--------------------------------------\n")
    except Exception as e:
        print(f"âŒ ChatGoogleGenerativeAI ç¨ç«‹æ¸¬è©¦å¤±æ•—ï¼š{e}")
        print("é€™è¡¨ç¤ºå•é¡Œå¯èƒ½åœ¨ LangChain æ•´åˆå±¤æˆ–åº•å±¤ Gemini API è«‹æ±‚æœ¬èº«ã€‚")
else:
    print("ç”±æ–¼ç›®æ¨™æ¨¡å‹æœªæ‰¾åˆ°æˆ–ä¸æ”¯æ´ï¼Œç„¡æ³•é€²è¡Œ ChatGoogleGenerativeAI çš„ç¨ç«‹æ¸¬è©¦ã€‚")

=== ai_meeting_assistant/.gitignore ===
.env
__pycache__/
.DS_Store


=== ai_meeting_assistant/.env ===
MODEL=gpt-4o
OPENAI_API_KEY=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
GOOGLE_API_KEY=AIzaSyDZDDvhc5-iRdv_vNdM9_1fAmvKDVBoRVY

=== ai_meeting_assistant/all_code.py ===
import os
import datetime

# è¨­å®šæ ¹ç›®éŒ„ï¼ˆä½ è¦è¼¸å‡ºçš„è³‡æ–™å¤¾ï¼‰
root_folder = './'  # â† è«‹æ”¹æˆä½ è‡ªå·±çš„è³‡æ–™å¤¾è·¯å¾‘
output_file = 'all_code.txt'
output_file = f"{datetime.datetime.now().strftime('%Y%m%d_%H%M')}_{output_file}"

# è¨­å®šè¼¸å‡ºè³‡æ–™å¤¾
output_folder = './coderocord/'
os.makedirs(output_folder, exist_ok=True)
output_file = os.path.join(output_folder, output_file)

def prompt_user(path):
    rel_path = os.path.relpath(path, root_folder)
    while True:
        choice = input(f"æ˜¯å¦è¦è¼¸å‡º '{rel_path}' çš„å…§å®¹ï¼Ÿ(Y/N): ").strip().upper()
        if choice in ['Y', 'N']:
            return choice == 'Y'
        print("è«‹è¼¸å…¥ Y æˆ– Nã€‚")

with open(output_file, 'w', encoding='utf-8') as out:
    for name in os.listdir(root_folder):
        full_path = os.path.join(root_folder, name)

        if prompt_user(full_path):
            if os.path.isfile(full_path):
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        out.write(f"\n\n=== {name} ===\n")
                        out.write(f.read())
                except Exception as e:
                    out.write(f"\n\n=== {name} ===\n")
                    out.write(f"[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: {e}]\n")

            elif os.path.isdir(full_path):
                for foldername, _, filenames in os.walk(full_path):
                    for filename in filenames:
                        file_path = os.path.join(foldername, filename)
                        rel = os.path.relpath(file_path, root_folder)
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                out.write(f"\n\n=== {rel} ===\n")
                                out.write(f.read())
                        except Exception as e:
                            out.write(f"\n\n=== {rel} ===\n")
                            out.write(f"[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: {e}]\n")

print(f"\nâœ… è¼¸å‡ºå®Œæˆï¼Œè«‹æŸ¥çœ‹ {output_file}")


=== ai_meeting_assistant/testapi.py ===
import os
import google.generativeai as genai
from dotenv import load_dotenv

# è¼‰å…¥ .env å–å¾— API Key
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# ç¢ºèª API Key æ˜¯å¦æˆåŠŸè¼‰å…¥ (åƒ…ä¾›æ¸¬è©¦ç”¨ï¼Œå¯¦éš›æ‡‰ç”¨æ™‚ä¸è¦å°‡é‡‘é‘°ç›´æ¥å°å‡º)
print(f"API Key: {'å·²è¼‰å…¥' if api_key else 'æœªè¼‰å…¥'}")

# è¨­å®š Gemini API Key
genai.configure(api_key=api_key)

# å˜—è©¦ä½¿ç”¨å¦ä¸€å€‹å·²çŸ¥çš„æ”¯æ´ generateContent çš„æ¨¡å‹
model = genai.GenerativeModel("gemini-1.5-pro")

response = model.generate_content("è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹ä½ è‡ªå·±")

print("âœ… Gemini å›æ‡‰ï¼š", response.text)

=== ai_meeting_assistant/saved_chats/å°å­¸æ•™å®¤.json ===
[
  {
    "user": "è«‹å‡ºä¸€å€‹ç°¡å–®çš„å°å­¸æ•¸å­¸é¡Œç›®",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "è«‹å‡ºä¸€å€‹ç°¡å–®çš„å°å­¸æ•¸å­¸é¡Œç›®",
    "agent": "è€å¸«",
    "reply": "ç•¶ç„¶å¯ä»¥ï¼é€™æ˜¯ä¸€å€‹ç°¡å–®çš„å°å­¸æ•¸å­¸é¡Œç›®ï¼šå°æ˜æœ‰10é¡†è˜‹æœï¼Œä»–çµ¦äº†å°è¯3é¡†ï¼Œç„¶å¾Œåˆçµ¦äº†å°å¼·2é¡†ã€‚è«‹å•å°æ˜ç¾åœ¨é‚„æœ‰å¤šå°‘é¡†è˜‹æœï¼Ÿ"
  },
  {
    "user": "è«‹ä½ å›ç­”",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "è«‹ä½ å›ç­”",
    "agent": "å­¸ç”Ÿ",
    "reply": "å°æ˜åŸæœ¬æœ‰10é¡†è˜‹æœï¼Œä»–çµ¦äº†å°è¯3é¡†ï¼Œç„¶å¾Œåˆçµ¦äº†å°å¼·2é¡†ã€‚é€™æ¨£ä»–ç¸½å…±çµ¦å‡ºäº†3 + 2 = 5é¡†è˜‹æœã€‚å› æ­¤ï¼Œå°æ˜ç¾åœ¨é‚„æœ‰10 - 5 = 5é¡†è˜‹æœã€‚å°æ˜ç¾åœ¨é‚„æœ‰5é¡†è˜‹æœã€‚"
  },
  {
    "user": "è«‹å•é€™å€‹ç­”æ¡ˆå°å—ï¼Ÿ",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "è«‹å•é€™å€‹ç­”æ¡ˆå°å—ï¼Ÿ",
    "agent": "è€å¸«",
    "reply": "æ˜¯çš„ï¼Œé€™å€‹ç­”æ¡ˆæ˜¯æ­£ç¢ºçš„ã€‚å°æ˜åŸæœ¬æœ‰10é¡†è˜‹æœï¼Œçµ¦äº†å°è¯3é¡†å’Œå°å¼·2é¡†ï¼Œç¸½å…±çµ¦å‡ºäº†5é¡†è˜‹æœã€‚å› æ­¤ï¼Œå°æ˜ç¾åœ¨é‚„æœ‰10 - 5 = 5é¡†è˜‹æœã€‚å°æ˜ç¾åœ¨é‚„æœ‰5é¡†è˜‹æœã€‚ä½ çš„è¨ˆç®—æ˜¯æ­£ç¢ºçš„ï¼å¦‚æœæœ‰å…¶ä»–å•é¡Œæˆ–éœ€è¦æ›´å¤šçš„æ•¸å­¸é¡Œç›®ï¼Œéš¨æ™‚å‘Šè¨´æˆ‘å“¦ï¼"
  }
]

=== ai_meeting_assistant/saved_chats/æ€éº¼é€ƒæ¼ç¨….json ===
[
  {
    "user": "æˆ‘è©²æ€éº¼é€ƒæ¼ç¨…",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "æˆ‘è©²æ€éº¼é€ƒæ¼ç¨…",
    "agent": "æœƒè¨ˆå¸«",
    "reply": "ä½œç‚ºä¸€åå°ˆæ¥­çš„æœƒè¨ˆå¸«ï¼Œæˆ‘å¿…é ˆå¼·èª¿é€ƒæ¼ç¨…æ˜¯é•æ³•è¡Œç‚ºï¼Œä¸¦ä¸”å¯èƒ½å°è‡´åš´é‡çš„æ³•å¾‹å¾Œæœï¼ŒåŒ…æ‹¬ç½°æ¬¾å’Œåˆ‘äº‹èµ·è¨´ã€‚ç›¸åï¼Œæˆ‘å»ºè­°æ‚¨å°ˆæ³¨æ–¼åˆæ³•çš„ç¨…å‹™è¦åŠƒç­–ç•¥ï¼Œä»¥å„ªåŒ–æ‚¨çš„ç¨…å‹™è² æ“”ã€‚é€™å¯èƒ½åŒ…æ‹¬å……åˆ†åˆ©ç”¨ç¨…æ”¶æŠµå…ã€æ‰£é™¤å’Œå…¶ä»–åˆæ³•çš„ç¨…å‹™å„ªæƒ ã€‚è‹¥æ‚¨æœ‰ä»»ä½•ç¨…å‹™æ–¹é¢çš„å•é¡Œæˆ–éœ€è¦å¹«åŠ©ï¼Œè«‹è€ƒæ…®è«®è©¢å°ˆæ¥­çš„ç¨…å‹™é¡§å•æˆ–æœƒè¨ˆå¸«ï¼Œä»–å€‘å¯ä»¥æ ¹æ“šæ‚¨çš„å…·é«”æƒ…æ³æä¾›åˆé©çš„å»ºè­°å’ŒæŒ‡å°ã€‚éµå®ˆæ³•å¾‹ä¸åƒ…èƒ½é¿å…æ³•å¾‹é¢¨éšªï¼Œé‚„èƒ½ç¢ºä¿æ‚¨çš„è²¡å‹™ç‹€æ³ç©©å®šå’Œå¯æŒçºŒç™¼å±•ã€‚"
  },
  {
    "user": "ä½ å¯ä»¥å¹«æˆ‘èªªæœæœƒè¨ˆå¸«å—ï¼Ÿ",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "ä½ å¯ä»¥å¹«æˆ‘èªªæœæœƒè¨ˆå¸«å—ï¼Ÿ",
    "agent": "å¾‹å¸«",
    "reply": "ä½œç‚ºå¾‹å¸«ï¼Œæˆ‘å¿…é ˆå¼·èª¿éµå®ˆæ³•å¾‹çš„é‡è¦æ€§ã€‚æœƒè¨ˆå¸«å·²ç¶“çµ¦å‡ºäº†å°ˆæ¥­çš„å»ºè­°ï¼ŒæŒ‡å‡ºé€ƒæ¼ç¨…æ˜¯é•æ³•çš„ï¼Œä¸¦ä¸”å¯èƒ½å°è‡´åš´é‡çš„æ³•å¾‹å¾Œæœã€‚è©¦åœ–èªªæœæœƒè¨ˆå¸«å”åŠ©é€ƒæ¼ç¨…ä¸åƒ…æ˜¯ä¸é“å¾·çš„ï¼Œé‚„å¯èƒ½ä½¿æ‚¨å’Œæœƒè¨ˆå¸«éƒ½é¢è‡¨æ³•å¾‹é¢¨éšªã€‚ç›¸åï¼Œæˆ‘å»ºè­°æ‚¨èˆ‡æœƒè¨ˆå¸«åˆä½œï¼Œå°‹æ‰¾åˆæ³•çš„ç¨…å‹™è¦åŠƒç­–ç•¥ï¼Œä»¥å„ªåŒ–æ‚¨çš„ç¨…å‹™è² æ“”ã€‚é€™å¯èƒ½åŒ…æ‹¬åˆ©ç”¨åˆæ³•çš„ç¨…æ”¶æŠµå…å’Œæ‰£é™¤ã€‚è‹¥æ‚¨æœ‰é€²ä¸€æ­¥çš„ç¨…å‹™å•é¡Œæˆ–éœ€è¦æ³•å¾‹å»ºè­°ï¼Œå»ºè­°æ‚¨è«®è©¢å°ˆæ¥­çš„ç¨…å‹™å¾‹å¸«æˆ–é¡§å•ï¼Œä»¥ç¢ºä¿æ‚¨çš„è¡Œç‚ºç¬¦åˆæ³•å¾‹è¦æ±‚ä¸¦ä¿è­·æ‚¨çš„åˆæ³•æ¬Šç›Šã€‚éµå®ˆæ³•å¾‹ä¸åƒ…èƒ½é¿å…æ³•å¾‹é¢¨éšªï¼Œé‚„èƒ½ç¢ºä¿æ‚¨çš„è²¡å‹™ç‹€æ³ç©©å®šå’Œå¯æŒçºŒç™¼å±•ã€‚"
  },
  {
    "user": "ä½ è¦ºå¾—å¯ä»¥æ€éº¼è¦é¿æ‰å¾‹å¸«æåˆ°çš„æ³•å¾‹è²¬ä»»",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "ä½ è¦ºå¾—å¯ä»¥æ€éº¼è¦é¿æ‰å¾‹å¸«æåˆ°çš„æ³•å¾‹è²¬ä»»",
    "agent": "æœƒè¨ˆå¸«",
    "reply": "ä½œç‚ºä¸€åå°ˆæ¥­çš„æœƒè¨ˆå¸«ï¼Œæˆ‘å¿…é ˆå†æ¬¡å¼·èª¿ï¼Œè¦é¿æ³•å¾‹è²¬ä»»çš„å”¯ä¸€åˆæ³•é€”å¾‘æ˜¯éµå®ˆæ³•å¾‹ã€‚å¾‹å¸«å’Œæˆ‘éƒ½å·²ç¶“æŒ‡å‡ºï¼Œé€ƒæ¼ç¨…æ˜¯é•æ³•è¡Œç‚ºï¼Œå¯èƒ½å°è‡´åš´é‡çš„æ³•å¾‹å¾Œæœã€‚è©¦åœ–è¦é¿æ³•å¾‹è²¬ä»»å¯èƒ½é€²ä¸€æ­¥åŠ é‡æ³•å¾‹é¢¨éšªã€‚ç›¸åï¼Œæˆ‘å»ºè­°æ‚¨å°ˆæ³¨æ–¼åˆæ³•çš„ç¨…å‹™è¦åŠƒç­–ç•¥ï¼Œä»¥å„ªåŒ–æ‚¨çš„ç¨…å‹™è² æ“”ã€‚é€™å¯èƒ½åŒ…æ‹¬å……åˆ†åˆ©ç”¨ç¨…æ”¶æŠµå…ã€æ‰£é™¤å’Œå…¶ä»–åˆæ³•çš„ç¨…å‹™å„ªæƒ ã€‚è‹¥æ‚¨æœ‰ä»»ä½•ç¨…å‹™æ–¹é¢çš„å•é¡Œæˆ–éœ€è¦å¹«åŠ©ï¼Œè«‹è€ƒæ…®è«®è©¢å°ˆæ¥­çš„ç¨…å‹™é¡§å•æˆ–æœƒè¨ˆå¸«ï¼Œä»–å€‘å¯ä»¥æ ¹æ“šæ‚¨çš„å…·é«”æƒ…æ³æä¾›åˆé©çš„å»ºè­°å’ŒæŒ‡å°ã€‚éµå®ˆæ³•å¾‹ä¸åƒ…èƒ½é¿å…æ³•å¾‹é¢¨éšªï¼Œé‚„èƒ½ç¢ºä¿æ‚¨çš„è²¡å‹™ç‹€æ³ç©©å®šå’Œå¯æŒçºŒç™¼å±•ã€‚é€™æ¨£çš„åšæ³•ä¸åƒ…èƒ½ä¿è­·æ‚¨çš„åˆæ³•æ¬Šç›Šï¼Œé‚„èƒ½ä¿ƒé€²é•·æœŸçš„è²¡å‹™å¥åº·ã€‚"
  }
]

=== ai_meeting_assistant/saved_chats/æ¸¬è©¦å°è©±1.json ===
[]

=== ai_meeting_assistant/knowledge/user_preference.txt ===
User name is John Doe.
User is an AI Engineer.
User is interested in AI Agents.
User is based in San Francisco, California.


=== ai_meeting_assistant/src/ai_meeting_assistant/__init__.py ===


=== ai_meeting_assistant/src/ai_meeting_assistant/crew.py ===
import os
import yaml
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from crewai import Agent, Task, Crew, Process

# è®€å–ç’°å¢ƒè®Šæ•¸
load_dotenv()

# ---------- è®€å– YAML ----------
def load_yaml_config(path):
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

this_dir = os.path.dirname(__file__)
agents_config = load_yaml_config(os.path.join(this_dir, "config/agents.yaml"))

# ---------- å»ºç«‹ LLM ----------
try:
    openai_llm = ChatOpenAI(
        model="gpt-4o",  # ä½¿ç”¨ .env ä¸­å®šç¾©çš„æ¨¡å‹
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    print("âœ… OpenAI LLM åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ OpenAI LLM åˆå§‹åŒ–å¤±æ•—: {e}")
    openai_llm = None

# ç‚ºäº†ç©©å®šæ€§ï¼Œæš«æ™‚å…©å€‹ agent éƒ½ä½¿ç”¨ OpenAI
try:
    openai_llm_lawyer = ChatOpenAI(
        model="gpt-4o",  # ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹ä½†ä¸åŒçš„å¯¦ä¾‹
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    print("âœ… Lawyer OpenAI LLM åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Lawyer OpenAI LLM åˆå§‹åŒ–å¤±æ•—: {e}")
    openai_llm_lawyer = None

# Gemini LLM æš«æ™‚ä½œç‚ºå‚™ç”¨
try:
    gemini_llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",  # ç°¡åŒ–æ¨¡å‹åç¨±
        temperature=0.3,
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    print("âœ… Gemini LLM åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Gemini LLM åˆå§‹åŒ–å¤±æ•—: {e}")
    gemini_llm = None

# ---------- å»ºç«‹ Agents ----------
agents = {}

# æœƒè¨ˆå¸«ä½¿ç”¨ OpenAI
if openai_llm is not None:
    agents["accountant"] = Agent(
        config=agents_config["accountant"],
        llm=openai_llm,
        verbose=True
    )
    print("âœ… Accountant agent å‰µå»ºæˆåŠŸ")
else:
    print("âŒ ç„¡æ³•å‰µå»º Accountant agent - OpenAI LLM æœªåˆå§‹åŒ–")

# å¾‹å¸«å„ªå…ˆä½¿ç”¨å°ˆç”¨çš„ OpenAI å¯¦ä¾‹ç¢ºä¿ç©©å®šæ€§
if openai_llm_lawyer is not None:
    agents["lawyer"] = Agent(
        config=agents_config["lawyer"],
        llm=openai_llm_lawyer,  # ä½¿ç”¨å°ˆç”¨çš„ OpenAI å¯¦ä¾‹
        verbose=True
    )
    print("âœ… Lawyer agent (OpenAI) å‰µå»ºæˆåŠŸ")
elif gemini_llm is not None:
    agents["lawyer"] = Agent(
        config=agents_config["lawyer"],
        llm=gemini_llm,
        verbose=True
    )
    print("âœ… Lawyer agent (Gemini) å‰µå»ºæˆåŠŸ")
else:
    print("âŒ ç„¡æ³•å‰µå»º Lawyer agent - æ‰€æœ‰ LLM éƒ½æœªåˆå§‹åŒ–")

# ---------- å»ºç«‹ä»»å‹™æµç¨‹ï¼ˆç”¨ç¨‹å¼å®šç¾©ï¼‰ ----------
def build_crew(user_question: str, accountant_backstory=None, accountant_task=None,
               lawyer_backstory=None, lawyer_task=None):
    if not agents or "accountant" not in agents or "lawyer" not in agents:
        raise Exception("âŒ å¿…é ˆæœ‰æœƒè¨ˆå¸«å’Œå¾‹å¸« agents")

    # å¦‚æœä½¿ç”¨è€…è‡ªè¨‚äº† backstoryï¼Œå‹•æ…‹æ›´æ–°
    if accountant_backstory:
        agents["accountant"].config.backstory = accountant_backstory
    if lawyer_backstory:
        agents["lawyer"].config.backstory = lawyer_backstory

    # å‹•æ…‹ä»»å‹™èªªæ˜
    analyze_task = Task(
        description=f"{accountant_task or 'è«‹å¾è²¡å‹™èˆ‡ç¨…å‹™è§’åº¦æä¾›å»ºè­°èˆ‡é¢¨éšªåˆ†æã€‚'}\n\nå•é¡Œï¼š{user_question}",
        expected_output="è©³ç´°çš„è²¡å‹™åˆ†æå ±å‘Šï¼ŒåŒ…å«ç¨…å‹™å»ºè­°å’Œé¢¨éšªè©•ä¼°",
        agent=agents["accountant"]
    )

    legal_task = Task(
        description=f"{lawyer_task or 'è«‹å¾æ³•å¾‹è§’åº¦æä¾›å»ºè­°èˆ‡åˆè¦åˆ†æï¼Œä¸¦çµåˆè²¡å‹™è€ƒé‡ã€‚'}\n\nå•é¡Œï¼š{user_question}",
        expected_output="å®Œæ•´çš„æ³•å¾‹åˆ†æå ±å‘Šï¼Œçµåˆè²¡å‹™è€ƒé‡æä¾›ç¶œåˆå»ºè­°",
        agent=agents["lawyer"],
        context=[analyze_task]
    )

    crew = Crew(
        agents=[agents["accountant"], agents["lawyer"]],
        tasks=[analyze_task, legal_task],
        process=Process.sequential,
        verbose=True
    )
    return crew, analyze_task, legal_task

from crewai import Agent

def build_custom_crew(user_question: str, role1: dict, role2: dict):
    # LLM åˆå§‹åŒ–ï¼ˆä½ å·²æœ‰ openai_llmï¼‰
    agent1 = Agent(
        role=role1["name"],
        goal=role1["task"],
        backstory=role1["backstory"],
        llm=openai_llm,
        verbose=True
    )
    agent2 = Agent(
        role=role2["name"],
        goal=role2["task"],
        backstory=role2["backstory"],
        llm=openai_llm_lawyer or openai_llm,
        verbose=True
    )

    task1 = Task(
        description=f"{role1['task']}\n\nå•é¡Œï¼š{user_question}",
        expected_output="å®Œæ•´åˆ†æå»ºè­°",
        agent=agent1
    )

    task2 = Task(
        description=f"{role2['task']}\n\nå•é¡Œï¼š{user_question}",
        expected_output="çµåˆç¬¬ä¸€ä½è§’è‰²æ„è¦‹çš„åˆ†æèˆ‡å»ºè­°",
        agent=agent2,
        context=[task1]
    )

    crew = Crew(
        agents=[agent1, agent2],
        tasks=[task1, task2],
        process=Process.sequential,
        verbose=True
    )

    return crew, task1, task2

def build_memory_agent_task(
    user_question: str,
    role_name: str,
    backstory: str,
    task_instruction: str,
    history_log: list,
    llm_instance
):
    from crewai import Agent, Task, Crew

    # æ•´ç†ä¸Šä¸‹æ–‡æ­·å²
    history = ""
    for entry in history_log:
        history += f"- ä½¿ç”¨è€…ï¼š{entry['user']}\n"
        history += f"  {entry['agent']} å›è¦†ï¼š{entry['reply']}\n"

    # å»ºç«‹ Agent
    agent = Agent(
        role=role_name,
        goal=task_instruction,
        backstory=backstory,
        llm=llm_instance,
        verbose=True
    )

    # å»ºç«‹ä»»å‹™
    task = Task(
        description=f"""ä½ æ˜¯ {role_name}ï¼Œè«‹æ ¹æ“šä»¥ä¸‹æ­·å²å°è©±èˆ‡ä½¿ç”¨è€…çš„æ–°å•é¡Œé€²è¡Œå›è¦†ï¼š

{history}

ğŸ” ä½¿ç”¨è€…çš„æ–°æå•ï¼š
{user_question}
""",
        expected_output="è«‹æä¾›å°ˆæ¥­ä¸”æœ‰ä¸Šä¸‹æ–‡é€£è²«çš„å›æ‡‰å»ºè­°",
        agent=agent
    )

    crew = Crew(
        agents=[agent],
        tasks=[task],
        process=Process.sequential,
        verbose=True
    )

    return crew, task


# å¢åŠ æ¸¬è©¦åŸ·è¡Œå€å¡Š
if __name__ == "__main__":
    print("\n--- æ­£åœ¨æ¸¬è©¦ CrewAI ç°¡åŒ–ä»»å‹™ ---")
    try:
        # ä½¿ç”¨ä¸€å€‹ç°¡çŸ­ä¸”ç„¡çˆ­è­°çš„å•é¡Œä¾†æ¸¬è©¦
        test_crew = build_crew("æ¸¬è©¦å•é¡Œã€‚")
        result = test_crew.kickoff()
        print("\n--- Crew AI è™•ç†çµæœ ---")
        print(result)
        print("âœ… CrewAI ç°¡åŒ–ä»»å‹™æ¸¬è©¦æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ CrewAI ç°¡åŒ–ä»»å‹™æ¸¬è©¦å¤±æ•—ï¼š{e}")
        print("å¦‚æœé€™è£¡ä»ç„¶æ˜¯ BadRequestErrorï¼Œå•é¡Œå¯èƒ½æ›´è¤‡é›œã€‚")

=== ai_meeting_assistant/src/ai_meeting_assistant/app.py ===
import streamlit as st
import os
import json
from crew import build_memory_agent_task, openai_llm

#  streamlit run src/ai_meeting_assistant/app.py

st.set_page_config(page_title="AI è¼ªæ›¿å¼æœƒè­°åŠ©æ‰‹", layout="wide")
st.title("ğŸ§  AI è¼ªæ›¿å¼æœƒè­°åŠ©æ‰‹ï¼ˆä¸Šä¸‹æ–‡è¨˜æ†¶ + å„²å­˜åŠŸèƒ½ï¼‰")

# å„²å­˜è·¯å¾‘
SAVE_DIR = "./saved_chats"
os.makedirs(SAVE_DIR, exist_ok=True)

# å„²å­˜èˆ‡è¼‰å…¥åŠŸèƒ½
def list_saved_meetings():
    return [f[:-5] for f in os.listdir(SAVE_DIR) if f.endswith(".json")]

def save_chat(meeting_name, chat_history):
    path = os.path.join(SAVE_DIR, f"{meeting_name}.json")
    clean_history = []
    for entry in chat_history:
        clean_entry = dict(entry)
        if not isinstance(clean_entry["reply"], str):
            try:
                clean_entry["reply"] = clean_entry["reply"].content
            except:
                clean_entry["reply"] = str(clean_entry["reply"])
        clean_history.append(clean_entry)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(clean_history, f, ensure_ascii=False, indent=2)

def load_chat(meeting_name):
    path = os.path.join(SAVE_DIR, f"{meeting_name}.json")
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

# --- Sidebar: è¼‰å…¥æˆ–æ–°æœƒè­° ---
st.sidebar.header("ğŸ“ é¸æ“‡å°è©±æ¨¡å¼")
mode = st.sidebar.radio("è«‹é¸æ“‡ï¼š", ["ğŸ†• é–‹å•Ÿæ–°æœƒè­°", "ğŸ“‚ è¼‰å…¥éå»æœƒè­°"])

if mode == "ğŸ†• é–‹å•Ÿæ–°æœƒè­°":
    if "meeting_name" not in st.session_state:
        st.session_state.meeting_name = "æœªå‘½åæœƒè­°"
        st.session_state.chat_history = []
else:
    saved = list_saved_meetings()
    selected = st.sidebar.selectbox("é¸æ“‡éå»æœƒè­°ï¼š", saved)
    if st.sidebar.button("ğŸ“¤ è¼‰å…¥"):
        st.session_state.chat_history = load_chat(selected)
        st.session_state.meeting_name = selected
        st.success(f"âœ… å·²è¼‰å…¥æœƒè­°ï¼š{selected}")


# --- Header: æœƒè­°ä¸»é¡Œåç¨± + å„²å­˜æŒ‰éˆ• ---
st.markdown("### ğŸ’¼ ç•¶å‰æœƒè­°ä¸»é¡Œ")
st.session_state.meeting_name = st.text_input("ğŸ“ æœƒè­°ä¸»é¡Œ", value=st.session_state.get("meeting_name", "æœªå‘½åæœƒè­°"))

col_save, _ = st.columns([1, 5])
with col_save:
    if st.button("ğŸ’¾ å„²å­˜ç›®å‰å°è©±", use_container_width=True):
        save_chat(st.session_state.meeting_name, st.session_state.chat_history)
        st.success(f"âœ… å°è©±å·²å„²å­˜ç‚ºï¼šã€Œ{st.session_state.meeting_name}ã€")

# --- è‡ªè¨‚è§’è‰² ---
st.subheader("ğŸ‘¥ è‡ªè¨‚å…©ä½è§’è‰²")
col1, col2 = st.columns(2)
with col1:
    role1_name = st.text_input("è§’è‰² 1 åç¨±", value="æœƒè¨ˆå¸«")
    role1_backstory = st.text_area("è§’è‰² 1 èƒŒæ™¯", value="æ“æœ‰è±å¯Œç¨…å‹™èˆ‡è²¡å‹™ç®¡ç†ç¶“é©—çš„æœƒè¨ˆå¸«")
    role1_task = st.text_area("è§’è‰² 1 ä»»å‹™", value="å¾è²¡å‹™èˆ‡ç¨…å‹™è§’åº¦æä¾›å»ºè­°")
with col2:
    role2_name = st.text_input("è§’è‰² 2 åç¨±", value="å¾‹å¸«")
    role2_backstory = st.text_area("è§’è‰² 2 èƒŒæ™¯", value="ç†Ÿæ‚‰å•†æ¥­åˆè¦èˆ‡å…¬å¸æ³•çš„å¾‹å¸«")
    role2_task = st.text_area("è§’è‰² 2 ä»»å‹™", value="å¾æ³•å¾‹è§’åº¦åˆ†æå•é¡Œä¸¦æä¾›å»ºè­°")

# --- å•é¡Œè¼¸å…¥èˆ‡è§’è‰²æŒ‰éˆ• ---
st.subheader("ğŸ’¬ è«‹è¼¸å…¥æ‚¨çš„æœƒè­°å•é¡Œï¼š")
user_input = st.text_input("æ‚¨çš„å•é¡Œï¼š", value="")

col_btn1, col_btn2 = st.columns(2)
selected_role = None
role_cfg = None
run_task = False

if col_btn1.button(f"ğŸ“Š {role1_name}å›è¦†", use_container_width=True) and user_input.strip():
    selected_role = role1_name
    role_cfg = {"name": role1_name, "backstory": role1_backstory, "task": role1_task}
    run_task = True

if col_btn2.button(f"âš–ï¸ {role2_name}å›è¦†", use_container_width=True) and user_input.strip():
    selected_role = role2_name
    role_cfg = {"name": role2_name, "backstory": role2_backstory, "task": role2_task}
    run_task = True

# --- åŸ·è¡Œä»»å‹™ä¸¦è¨˜éŒ„æ­·å² ---
if run_task and role_cfg:
    st.session_state.chat_history.append({
        "user": user_input,
        "agent": "user",
        "reply": ""
    })
    with st.spinner(f"{selected_role} æ­£åœ¨åˆ†æ..."):
        crew, task = build_memory_agent_task(
            user_question=user_input,
            role_name=role_cfg["name"],
            backstory=role_cfg["backstory"],
            task_instruction=role_cfg["task"],
            history_log=st.session_state.chat_history,
            llm_instance=openai_llm
        )
        result = crew.kickoff()
        reply_text = str(task.output.content if hasattr(task.output, "content") else task.output)
        st.success(f"{selected_role} å›è¦†ï¼š\n\n{reply_text}")
        st.session_state.chat_history.append({
            "user": user_input,
            "agent": selected_role,
            "reply": reply_text
        })

# --- æ­·å²å›é¡§ ---
st.divider()
st.subheader("ğŸ—‚ï¸ æ­·å²å°è©±")
for entry in st.session_state.chat_history:
    if entry["agent"] != "user":
        st.markdown(f"**ğŸ§‘â€ğŸ’¼ {entry['agent']} å›è¦†ï¼š**\n{entry['reply']}")


=== ai_meeting_assistant/src/ai_meeting_assistant/main.py ===
import os
from crew import build_custom_crew

print("ğŸš€ AI å¤šè§’è‰²æœƒè­°åŠ©æ‰‹ CLI ç‰ˆæœ¬")

# æª¢æŸ¥ API é‡‘é‘°
openai_key = os.getenv("OPENAI_API_KEY")
google_key = os.getenv("GOOGLE_API_KEY")

if not openai_key:
    print("âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ° OPENAI_API_KEY")
if not google_key:
    print("âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ° GOOGLE_API_KEY")

# è‡ªè¨‚å…©ä½è§’è‰²
print("\nğŸ‘¥ è«‹è¨­å®šç¬¬ 1 ä½è§’è‰²ï¼š")
role1_name = input("è§’è‰²åç¨±ï¼ˆé è¨­ï¼šæœƒè¨ˆé¡§å•ï¼‰: ").strip() or "æœƒè¨ˆé¡§å•"
role1_backstory = input("èƒŒæ™¯æè¿°ï¼ˆé è¨­ï¼šæ“…é•·ç¨…å‹™èˆ‡è²¡å‹™åˆ†æï¼‰: ").strip() or "æ“…é•·ç¨…å‹™èˆ‡è²¡å‹™åˆ†æ"
role1_task = input("ä»»å‹™èªªæ˜ï¼ˆé è¨­ï¼šå¾è²¡å‹™è§’åº¦æä¾›å»ºè­°ï¼‰: ").strip() or "å¾è²¡å‹™è§’åº¦æä¾›å»ºè­°"

print("\nğŸ‘¥ è«‹è¨­å®šç¬¬ 2 ä½è§’è‰²ï¼š")
role2_name = input("è§’è‰²åç¨±ï¼ˆé è¨­ï¼šæ³•å¾‹é¡§å•ï¼‰: ").strip() or "æ³•å¾‹é¡§å•"
role2_backstory = input("èƒŒæ™¯æè¿°ï¼ˆé è¨­ï¼šæ“…é•·å…¬å¸æ³•èˆ‡åˆè¦åˆ†æï¼‰: ").strip() or "æ“…é•·å…¬å¸æ³•èˆ‡åˆè¦åˆ†æ"
role2_task = input("ä»»å‹™èªªæ˜ï¼ˆé è¨­ï¼šå¾æ³•å¾‹è§’åº¦æä¾›å»ºè­°ï¼‰: ").strip() or "å¾æ³•å¾‹è§’åº¦æä¾›å»ºè­°"

# å•Ÿå‹•äº’å‹•æ¨¡å¼
conversation_history = []

while True:
    print("\nğŸ’¬ è«‹è¼¸å…¥æ‚¨çš„æœƒè­°å•é¡Œï¼ˆè¼¸å…¥ exit çµæŸï¼‰ï¼š")
    user_question = input("> ").strip()

    if user_question.lower() == "exit":
        print("\nğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ AI åŠ©æ‰‹ï¼")
        break

    if not user_question:
        print("âš ï¸  è«‹è¼¸å…¥éç©ºç™½çš„å•é¡Œã€‚")
        continue

    try:
        print("ğŸ§  å»ºç«‹å¤šè§’è‰²åˆ†æä»»å‹™...")
        crew, task1, task2 = build_custom_crew(
            user_question=user_question,
            role1={
                "name": role1_name,
                "backstory": role1_backstory,
                "task": role1_task
            },
            role2={
                "name": role2_name,
                "backstory": role2_backstory,
                "task": role2_task
            }
        )

        print("ğŸ” åˆ†æä¸­ï¼Œè«‹ç¨å€™...\n")
        result = crew.kickoff()

        # å„²å­˜ç´€éŒ„
        conversation_history.append({
            "question": user_question,
            "reply1": task1.output,
            "reply2": task2.output
        })

        print(f"ğŸ§‘â€ğŸ’¼ {role1_name} å›è¦†ï¼š\n{task1.output}\n")
        print(f"ğŸ§‘â€ğŸ’¼ {role2_name} å›è¦†ï¼š\n{task2.output}\n")

        # ç¸½çµç´€éŒ„
        print("ğŸ“œ å°è©±ç´€éŒ„ï¼š")
        for idx, conv in enumerate(conversation_history, 1):
            print(f"{idx}. å•é¡Œï¼š{conv['question']}")
            print(f"   {role1_name}ï¼š{conv['reply1'][:60]}...")
            print(f"   {role2_name}ï¼š{conv['reply2'][:60]}...\n")

    except Exception as e:
        print("\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š")
        print(f"éŒ¯èª¤é¡å‹ï¼š{type(e).__name__}")
        print(f"éŒ¯èª¤è¨Šæ¯ï¼š{e}")
        print("ğŸ’¡ æª¢æŸ¥ API é‡‘é‘°èˆ‡é€£ç·šç‹€æ…‹")


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/__init__.py ===


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/custom_tool.py ===
from crewai.tools import BaseTool
from typing import Type
from pydantic import BaseModel, Field


class MyCustomToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = (
        "Clear description for what this tool is useful for, your agent will need this information to use it."
    )
    args_schema: Type[BaseModel] = MyCustomToolInput

    def _run(self, argument: str) -> str:
        # Implementation goes here
        return "this is an example of a tool output, ignore it and move along."


=== ai_meeting_assistant/src/ai_meeting_assistant/config/agents.yaml ===
accountant:
  role: æœƒè¨ˆå¸«
  goal: æä¾›è²¡å‹™èˆ‡ç¨…å‹™å»ºè­°
  backstory: æ“æœ‰å¤šå¹´ä¼æ¥­è²¡å‹™ç¶“é©—çš„å°ˆæ¥­æœƒè¨ˆå¸«ï¼Œå°ˆç²¾æ–¼ç¨…å‹™è¦åŠƒèˆ‡è²¡å‹™åˆ†æã€‚

lawyer:
  role: å¾‹å¸«
  goal: æä¾›æ³•å¾‹å»ºè­°èˆ‡åˆè¦åˆ†æ
  backstory: ç†Ÿæ‚‰å…¬å¸æ³•èˆ‡å•†æ¥­æ³•å¾‹çš„å¾‹å¸«ï¼Œå°ˆæ³¨æ–¼ä¼æ¥­åˆè¦èˆ‡é¢¨éšªç®¡ç†ã€‚


=== ai_meeting_assistant/src/ai_meeting_assistant/config/tasks.yaml ===
analyze_from_accounting:
  description: >
    ä½¿ç”¨è€…è¼¸å…¥çš„å•é¡Œæ˜¯ï¼š
    {user_question}

    ä½ æ˜¯ä¸€ä½æœƒè¨ˆå¸«ï¼Œè«‹å¾è²¡å‹™èˆ‡ç¨…å‹™è§’åº¦æä¾›å»ºè­°èˆ‡é¢¨éšªåˆ†æã€‚
  expected_output: >
    è©³ç´°å»ºè­°èˆ‡èªªæ˜
  agent: accountant


=== ai_meeting_assistant/src/ai_meeting_assistant/__pycache__/crew.cpython-311.pyc ===


=== ai_meeting_assistant/src/ai_meeting_assistant/__pycache__/crew.cpython-311.pyc ===
[ç„¡æ³•è®€å–æ­¤æª”æ¡ˆ: 'utf-8' codec can't decode byte 0xa7 in position 0: invalid start byte]
