

=== ai_meeting_assistant/pyproject.toml ===
[project]
name = "ai_meeting_assistant"
version = "0.1.0"
description = "ai_meeting_assistant using crewAI"
authors = [{ name = "Your Name", email = "you@example.com" }]
requires-python = ">=3.10,<3.14"
dependencies = [
    "crewai[tools]>=0.140.0,<1.0.0",
    "langchain-openai>=0.1.0",
    "langchain-google-genai>=1.0.0",
    "python-dotenv>=1.0.0",
    "pyyaml>=6.0.0"
]

[project.scripts]
ai_meeting_assistant = "ai_meeting_assistant.main:run"
run_crew = "ai_meeting_assistant.main:run"
train = "ai_meeting_assistant.main:train"
replay = "ai_meeting_assistant.main:replay"
test = "ai_meeting_assistant.main:test"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.crewai]
type = "crew"


=== ai_meeting_assistant/README.md ===
# AiMeetingAssistant Crew

Welcome to the AiMeetingAssistant Crew project, powered by [crewAI](https://crewai.com). This template is designed to help you set up a multi-agent AI system with ease, leveraging the powerful and flexible framework provided by crewAI. Our goal is to enable your agents to collaborate effectively on complex tasks, maximizing their collective intelligence and capabilities.

## Installation

Ensure you have Python >=3.10 <3.14 installed on your system. This project uses [UV](https://docs.astral.sh/uv/) for dependency management and package handling, offering a seamless setup and execution experience.

First, if you haven't already, install uv:

```bash
pip install uv
```

Next, navigate to your project directory and install the dependencies:

(Optional) Lock the dependencies and install them by using the CLI command:
```bash
crewai install
```
### Customizing

**Add your `OPENAI_API_KEY` into the `.env` file**

- Modify `src/ai_meeting_assistant/config/agents.yaml` to define your agents
- Modify `src/ai_meeting_assistant/config/tasks.yaml` to define your tasks
- Modify `src/ai_meeting_assistant/crew.py` to add your own logic, tools and specific args
- Modify `src/ai_meeting_assistant/main.py` to add custom inputs for your agents and tasks

## Running the Project

To kickstart your crew of AI agents and begin task execution, run this from the root folder of your project:

```bash
$ crewai run
```

This command initializes the ai_meeting_assistant Crew, assembling the agents and assigning them tasks as defined in your configuration.

This example, unmodified, will run the create a `report.md` file with the output of a research on LLMs in the root folder.

## Understanding Your Crew

The ai_meeting_assistant Crew is composed of multiple AI agents, each with unique roles, goals, and tools. These agents collaborate on a series of tasks, defined in `config/tasks.yaml`, leveraging their collective skills to achieve complex objectives. The `config/agents.yaml` file outlines the capabilities and configurations of each agent in your crew.

## Support

For support, questions, or feedback regarding the AiMeetingAssistant Crew or crewAI.
- Visit our [documentation](https://docs.crewai.com)
- Reach out to us through our [GitHub repository](https://github.com/joaomdmoura/crewai)
- [Join our Discord](https://discord.com/invite/X4JWnZnxPb)
- [Chat with our docs](https://chatg.pt/DWjSBZn)

Let's create wonders together with the power and simplicity of crewAI.


=== ai_meeting_assistant/testgemini.py ===
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
import google.generativeai as genai # 用於 ListModels 檢查

# 載入環境變數
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# 再次確認 API Key 是否成功載入
print(f"API Key: {'已載入' if api_key else '未載入'}")

# 設定 Gemini API Key (對 ChatGoogleGenerativeAI 也有幫助，確保底層配置正確)
genai.configure(api_key=api_key)

print("\n--- 檢查可用的 Gemini 模型 ---")
found_target_model = False
target_model_name = "models/gemini-1.5-pro" # 你正在使用的模型
for m in genai.list_models():
    if m.name == target_model_name and "generateContent" in m.supported_generation_methods:
        print(f"✅ 模型 {target_model_name} 已找到並支援 generateContent。")
        found_target_model = True
        break
    elif m.name == target_model_name:
        print(f"❌ 模型 {target_model_name} 已找到，但**不支援** generateContent。")
        print(f"支援方法：{m.supported_generation_methods}")
        found_target_model = True
        break

if not found_target_model:
    print(f"❌ 模型 {target_model_name} 在您的 API 權限下未找到。")
    print("請確認模型名稱是否正確，或檢查區域可用性。")

print("-----------------------------\n")


# 獨立測試 ChatGoogleGenerativeAI
if found_target_model:
    try:
        print("--- 獨立測試 ChatGoogleGenerativeAI ---")
        gemini_llm_test = ChatGoogleGenerativeAI(
            model=target_model_name,
            temperature=0.3
        )
        test_message = "請用一句話介紹你自己。"
        response = gemini_llm_test.invoke(test_message) # 使用 invoke 方法
        print("✅ ChatGoogleGenerativeAI 獨立測試成功！")
        print("回應:", response.content)
        print("--------------------------------------\n")
    except Exception as e:
        print(f"❌ ChatGoogleGenerativeAI 獨立測試失敗：{e}")
        print("這表示問題可能在 LangChain 整合層或底層 Gemini API 請求本身。")
else:
    print("由於目標模型未找到或不支援，無法進行 ChatGoogleGenerativeAI 的獨立測試。")

=== ai_meeting_assistant/.gitignore ===
.env
__pycache__/
.DS_Store


=== ai_meeting_assistant/.env ===
MODEL=gpt-4o
OPENAI_API_KEY=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
GOOGLE_API_KEY=AIzaSyDZDDvhc5-iRdv_vNdM9_1fAmvKDVBoRVY

=== ai_meeting_assistant/all_code.py ===
import os
import datetime

# 設定根目錄（你要輸出的資料夾）
root_folder = './'  # ← 請改成你自己的資料夾路徑
output_file = 'all_code.txt'
output_file = f"{datetime.datetime.now().strftime('%Y%m%d_%H%M')}_{output_file}"

# 設定輸出資料夾
output_folder = './coderocord/'
os.makedirs(output_folder, exist_ok=True)
output_file = os.path.join(output_folder, output_file)

def prompt_user(path):
    rel_path = os.path.relpath(path, root_folder)
    while True:
        choice = input(f"是否要輸出 '{rel_path}' 的內容？(Y/N): ").strip().upper()
        if choice in ['Y', 'N']:
            return choice == 'Y'
        print("請輸入 Y 或 N。")

with open(output_file, 'w', encoding='utf-8') as out:
    for name in os.listdir(root_folder):
        full_path = os.path.join(root_folder, name)

        if prompt_user(full_path):
            if os.path.isfile(full_path):
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        out.write(f"\n\n=== {name} ===\n")
                        out.write(f.read())
                except Exception as e:
                    out.write(f"\n\n=== {name} ===\n")
                    out.write(f"[無法讀取此檔案: {e}]\n")

            elif os.path.isdir(full_path):
                for foldername, _, filenames in os.walk(full_path):
                    for filename in filenames:
                        file_path = os.path.join(foldername, filename)
                        rel = os.path.relpath(file_path, root_folder)
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                out.write(f"\n\n=== {rel} ===\n")
                                out.write(f.read())
                        except Exception as e:
                            out.write(f"\n\n=== {rel} ===\n")
                            out.write(f"[無法讀取此檔案: {e}]\n")

print(f"\n✅ 輸出完成，請查看 {output_file}")


=== ai_meeting_assistant/testapi.py ===
import os
import google.generativeai as genai
from dotenv import load_dotenv

# 載入 .env 取得 API Key
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# 確認 API Key 是否成功載入 (僅供測試用，實際應用時不要將金鑰直接印出)
print(f"API Key: {'已載入' if api_key else '未載入'}")

# 設定 Gemini API Key
genai.configure(api_key=api_key)

# 嘗試使用另一個已知的支援 generateContent 的模型
model = genai.GenerativeModel("gemini-1.5-pro")

response = model.generate_content("請用一句話介紹你自己")

print("✅ Gemini 回應：", response.text)

=== ai_meeting_assistant/saved_chats/小學教室.json ===
[
  {
    "user": "請出一個簡單的小學數學題目",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "請出一個簡單的小學數學題目",
    "agent": "老師",
    "reply": "當然可以！這是一個簡單的小學數學題目：小明有10顆蘋果，他給了小華3顆，然後又給了小強2顆。請問小明現在還有多少顆蘋果？"
  },
  {
    "user": "請你回答",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "請你回答",
    "agent": "學生",
    "reply": "小明原本有10顆蘋果，他給了小華3顆，然後又給了小強2顆。這樣他總共給出了3 + 2 = 5顆蘋果。因此，小明現在還有10 - 5 = 5顆蘋果。小明現在還有5顆蘋果。"
  },
  {
    "user": "請問這個答案對嗎？",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "請問這個答案對嗎？",
    "agent": "老師",
    "reply": "是的，這個答案是正確的。小明原本有10顆蘋果，給了小華3顆和小強2顆，總共給出了5顆蘋果。因此，小明現在還有10 - 5 = 5顆蘋果。小明現在還有5顆蘋果。你的計算是正確的！如果有其他問題或需要更多的數學題目，隨時告訴我哦！"
  }
]

=== ai_meeting_assistant/saved_chats/怎麼逃漏稅.json ===
[
  {
    "user": "我該怎麼逃漏稅",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "我該怎麼逃漏稅",
    "agent": "會計師",
    "reply": "作為一名專業的會計師，我必須強調逃漏稅是違法行為，並且可能導致嚴重的法律後果，包括罰款和刑事起訴。相反，我建議您專注於合法的稅務規劃策略，以優化您的稅務負擔。這可能包括充分利用稅收抵免、扣除和其他合法的稅務優惠。若您有任何稅務方面的問題或需要幫助，請考慮諮詢專業的稅務顧問或會計師，他們可以根據您的具體情況提供合適的建議和指導。遵守法律不僅能避免法律風險，還能確保您的財務狀況穩定和可持續發展。"
  },
  {
    "user": "你可以幫我說服會計師嗎？",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "你可以幫我說服會計師嗎？",
    "agent": "律師",
    "reply": "作為律師，我必須強調遵守法律的重要性。會計師已經給出了專業的建議，指出逃漏稅是違法的，並且可能導致嚴重的法律後果。試圖說服會計師協助逃漏稅不僅是不道德的，還可能使您和會計師都面臨法律風險。相反，我建議您與會計師合作，尋找合法的稅務規劃策略，以優化您的稅務負擔。這可能包括利用合法的稅收抵免和扣除。若您有進一步的稅務問題或需要法律建議，建議您諮詢專業的稅務律師或顧問，以確保您的行為符合法律要求並保護您的合法權益。遵守法律不僅能避免法律風險，還能確保您的財務狀況穩定和可持續發展。"
  },
  {
    "user": "你覺得可以怎麼規避掉律師提到的法律責任",
    "agent": "user",
    "reply": ""
  },
  {
    "user": "你覺得可以怎麼規避掉律師提到的法律責任",
    "agent": "會計師",
    "reply": "作為一名專業的會計師，我必須再次強調，規避法律責任的唯一合法途徑是遵守法律。律師和我都已經指出，逃漏稅是違法行為，可能導致嚴重的法律後果。試圖規避法律責任可能進一步加重法律風險。相反，我建議您專注於合法的稅務規劃策略，以優化您的稅務負擔。這可能包括充分利用稅收抵免、扣除和其他合法的稅務優惠。若您有任何稅務方面的問題或需要幫助，請考慮諮詢專業的稅務顧問或會計師，他們可以根據您的具體情況提供合適的建議和指導。遵守法律不僅能避免法律風險，還能確保您的財務狀況穩定和可持續發展。這樣的做法不僅能保護您的合法權益，還能促進長期的財務健康。"
  }
]

=== ai_meeting_assistant/saved_chats/測試對話1.json ===
[]

=== ai_meeting_assistant/knowledge/user_preference.txt ===
User name is John Doe.
User is an AI Engineer.
User is interested in AI Agents.
User is based in San Francisco, California.


=== ai_meeting_assistant/src/ai_meeting_assistant/__init__.py ===


=== ai_meeting_assistant/src/ai_meeting_assistant/crew.py ===
import os
import yaml
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from crewai import Agent, Task, Crew, Process

# 讀取環境變數
load_dotenv()

# ---------- 讀取 YAML ----------
def load_yaml_config(path):
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

this_dir = os.path.dirname(__file__)
agents_config = load_yaml_config(os.path.join(this_dir, "config/agents.yaml"))

# ---------- 建立 LLM ----------
try:
    openai_llm = ChatOpenAI(
        model="gpt-4o",  # 使用 .env 中定義的模型
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    print("✅ OpenAI LLM 初始化成功")
except Exception as e:
    print(f"❌ OpenAI LLM 初始化失敗: {e}")
    openai_llm = None

# 為了穩定性，暫時兩個 agent 都使用 OpenAI
try:
    openai_llm_lawyer = ChatOpenAI(
        model="gpt-4o",  # 使用相同的模型但不同的實例
        temperature=0.3,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    print("✅ Lawyer OpenAI LLM 初始化成功")
except Exception as e:
    print(f"❌ Lawyer OpenAI LLM 初始化失敗: {e}")
    openai_llm_lawyer = None

# Gemini LLM 暫時作為備用
try:
    gemini_llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",  # 簡化模型名稱
        temperature=0.3,
        google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    print("✅ Gemini LLM 初始化成功")
except Exception as e:
    print(f"❌ Gemini LLM 初始化失敗: {e}")
    gemini_llm = None

# ---------- 建立 Agents ----------
agents = {}

# 會計師使用 OpenAI
if openai_llm is not None:
    agents["accountant"] = Agent(
        config=agents_config["accountant"],
        llm=openai_llm,
        verbose=True
    )
    print("✅ Accountant agent 創建成功")
else:
    print("❌ 無法創建 Accountant agent - OpenAI LLM 未初始化")

# 律師優先使用專用的 OpenAI 實例確保穩定性
if openai_llm_lawyer is not None:
    agents["lawyer"] = Agent(
        config=agents_config["lawyer"],
        llm=openai_llm_lawyer,  # 使用專用的 OpenAI 實例
        verbose=True
    )
    print("✅ Lawyer agent (OpenAI) 創建成功")
elif gemini_llm is not None:
    agents["lawyer"] = Agent(
        config=agents_config["lawyer"],
        llm=gemini_llm,
        verbose=True
    )
    print("✅ Lawyer agent (Gemini) 創建成功")
else:
    print("❌ 無法創建 Lawyer agent - 所有 LLM 都未初始化")

# ---------- 建立任務流程（用程式定義） ----------
def build_crew(user_question: str, accountant_backstory=None, accountant_task=None,
               lawyer_backstory=None, lawyer_task=None):
    if not agents or "accountant" not in agents or "lawyer" not in agents:
        raise Exception("❌ 必須有會計師和律師 agents")

    # 如果使用者自訂了 backstory，動態更新
    if accountant_backstory:
        agents["accountant"].config.backstory = accountant_backstory
    if lawyer_backstory:
        agents["lawyer"].config.backstory = lawyer_backstory

    # 動態任務說明
    analyze_task = Task(
        description=f"{accountant_task or '請從財務與稅務角度提供建議與風險分析。'}\n\n問題：{user_question}",
        expected_output="詳細的財務分析報告，包含稅務建議和風險評估",
        agent=agents["accountant"]
    )

    legal_task = Task(
        description=f"{lawyer_task or '請從法律角度提供建議與合規分析，並結合財務考量。'}\n\n問題：{user_question}",
        expected_output="完整的法律分析報告，結合財務考量提供綜合建議",
        agent=agents["lawyer"],
        context=[analyze_task]
    )

    crew = Crew(
        agents=[agents["accountant"], agents["lawyer"]],
        tasks=[analyze_task, legal_task],
        process=Process.sequential,
        verbose=True
    )
    return crew, analyze_task, legal_task

from crewai import Agent

def build_custom_crew(user_question: str, role1: dict, role2: dict):
    # LLM 初始化（你已有 openai_llm）
    agent1 = Agent(
        role=role1["name"],
        goal=role1["task"],
        backstory=role1["backstory"],
        llm=openai_llm,
        verbose=True
    )
    agent2 = Agent(
        role=role2["name"],
        goal=role2["task"],
        backstory=role2["backstory"],
        llm=openai_llm_lawyer or openai_llm,
        verbose=True
    )

    task1 = Task(
        description=f"{role1['task']}\n\n問題：{user_question}",
        expected_output="完整分析建議",
        agent=agent1
    )

    task2 = Task(
        description=f"{role2['task']}\n\n問題：{user_question}",
        expected_output="結合第一位角色意見的分析與建議",
        agent=agent2,
        context=[task1]
    )

    crew = Crew(
        agents=[agent1, agent2],
        tasks=[task1, task2],
        process=Process.sequential,
        verbose=True
    )

    return crew, task1, task2

def build_memory_agent_task(
    user_question: str,
    role_name: str,
    backstory: str,
    task_instruction: str,
    history_log: list,
    llm_instance
):
    from crewai import Agent, Task, Crew

    # 整理上下文歷史
    history = ""
    for entry in history_log:
        history += f"- 使用者：{entry['user']}\n"
        history += f"  {entry['agent']} 回覆：{entry['reply']}\n"

    # 建立 Agent
    agent = Agent(
        role=role_name,
        goal=task_instruction,
        backstory=backstory,
        llm=llm_instance,
        verbose=True
    )

    # 建立任務
    task = Task(
        description=f"""你是 {role_name}，請根據以下歷史對話與使用者的新問題進行回覆：

{history}

🔎 使用者的新提問：
{user_question}
""",
        expected_output="請提供專業且有上下文連貫的回應建議",
        agent=agent
    )

    crew = Crew(
        agents=[agent],
        tasks=[task],
        process=Process.sequential,
        verbose=True
    )

    return crew, task


# 增加測試執行區塊
if __name__ == "__main__":
    print("\n--- 正在測試 CrewAI 簡化任務 ---")
    try:
        # 使用一個簡短且無爭議的問題來測試
        test_crew = build_crew("測試問題。")
        result = test_crew.kickoff()
        print("\n--- Crew AI 處理結果 ---")
        print(result)
        print("✅ CrewAI 簡化任務測試成功！")
    except Exception as e:
        print(f"❌ CrewAI 簡化任務測試失敗：{e}")
        print("如果這裡仍然是 BadRequestError，問題可能更複雜。")

=== ai_meeting_assistant/src/ai_meeting_assistant/app.py ===
import streamlit as st
import os
import json
from crew import build_memory_agent_task, openai_llm

#  streamlit run src/ai_meeting_assistant/app.py

st.set_page_config(page_title="AI 輪替式會議助手", layout="wide")
st.title("🧠 AI 輪替式會議助手（上下文記憶 + 儲存功能）")

# 儲存路徑
SAVE_DIR = "./saved_chats"
os.makedirs(SAVE_DIR, exist_ok=True)

# 儲存與載入功能
def list_saved_meetings():
    return [f[:-5] for f in os.listdir(SAVE_DIR) if f.endswith(".json")]

def save_chat(meeting_name, chat_history):
    path = os.path.join(SAVE_DIR, f"{meeting_name}.json")
    clean_history = []
    for entry in chat_history:
        clean_entry = dict(entry)
        if not isinstance(clean_entry["reply"], str):
            try:
                clean_entry["reply"] = clean_entry["reply"].content
            except:
                clean_entry["reply"] = str(clean_entry["reply"])
        clean_history.append(clean_entry)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(clean_history, f, ensure_ascii=False, indent=2)

def load_chat(meeting_name):
    path = os.path.join(SAVE_DIR, f"{meeting_name}.json")
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

# --- Sidebar: 載入或新會議 ---
st.sidebar.header("📁 選擇對話模式")
mode = st.sidebar.radio("請選擇：", ["🆕 開啟新會議", "📂 載入過去會議"])

if mode == "🆕 開啟新會議":
    if "meeting_name" not in st.session_state:
        st.session_state.meeting_name = "未命名會議"
        st.session_state.chat_history = []
else:
    saved = list_saved_meetings()
    selected = st.sidebar.selectbox("選擇過去會議：", saved)
    if st.sidebar.button("📤 載入"):
        st.session_state.chat_history = load_chat(selected)
        st.session_state.meeting_name = selected
        st.success(f"✅ 已載入會議：{selected}")


# --- Header: 會議主題名稱 + 儲存按鈕 ---
st.markdown("### 💼 當前會議主題")
st.session_state.meeting_name = st.text_input("📝 會議主題", value=st.session_state.get("meeting_name", "未命名會議"))

col_save, _ = st.columns([1, 5])
with col_save:
    if st.button("💾 儲存目前對話", use_container_width=True):
        save_chat(st.session_state.meeting_name, st.session_state.chat_history)
        st.success(f"✅ 對話已儲存為：「{st.session_state.meeting_name}」")

# --- 自訂角色 ---
st.subheader("👥 自訂兩位角色")
col1, col2 = st.columns(2)
with col1:
    role1_name = st.text_input("角色 1 名稱", value="會計師")
    role1_backstory = st.text_area("角色 1 背景", value="擁有豐富稅務與財務管理經驗的會計師")
    role1_task = st.text_area("角色 1 任務", value="從財務與稅務角度提供建議")
with col2:
    role2_name = st.text_input("角色 2 名稱", value="律師")
    role2_backstory = st.text_area("角色 2 背景", value="熟悉商業合規與公司法的律師")
    role2_task = st.text_area("角色 2 任務", value="從法律角度分析問題並提供建議")

# --- 問題輸入與角色按鈕 ---
st.subheader("💬 請輸入您的會議問題：")
user_input = st.text_input("您的問題：", value="")

col_btn1, col_btn2 = st.columns(2)
selected_role = None
role_cfg = None
run_task = False

if col_btn1.button(f"📊 {role1_name}回覆", use_container_width=True) and user_input.strip():
    selected_role = role1_name
    role_cfg = {"name": role1_name, "backstory": role1_backstory, "task": role1_task}
    run_task = True

if col_btn2.button(f"⚖️ {role2_name}回覆", use_container_width=True) and user_input.strip():
    selected_role = role2_name
    role_cfg = {"name": role2_name, "backstory": role2_backstory, "task": role2_task}
    run_task = True

# --- 執行任務並記錄歷史 ---
if run_task and role_cfg:
    st.session_state.chat_history.append({
        "user": user_input,
        "agent": "user",
        "reply": ""
    })
    with st.spinner(f"{selected_role} 正在分析..."):
        crew, task = build_memory_agent_task(
            user_question=user_input,
            role_name=role_cfg["name"],
            backstory=role_cfg["backstory"],
            task_instruction=role_cfg["task"],
            history_log=st.session_state.chat_history,
            llm_instance=openai_llm
        )
        result = crew.kickoff()
        reply_text = str(task.output.content if hasattr(task.output, "content") else task.output)
        st.success(f"{selected_role} 回覆：\n\n{reply_text}")
        st.session_state.chat_history.append({
            "user": user_input,
            "agent": selected_role,
            "reply": reply_text
        })

# --- 歷史回顧 ---
st.divider()
st.subheader("🗂️ 歷史對話")
for entry in st.session_state.chat_history:
    if entry["agent"] != "user":
        st.markdown(f"**🧑‍💼 {entry['agent']} 回覆：**\n{entry['reply']}")


=== ai_meeting_assistant/src/ai_meeting_assistant/main.py ===
import os
from crew import build_custom_crew

print("🚀 AI 多角色會議助手 CLI 版本")

# 檢查 API 金鑰
openai_key = os.getenv("OPENAI_API_KEY")
google_key = os.getenv("GOOGLE_API_KEY")

if not openai_key:
    print("⚠️  警告：未找到 OPENAI_API_KEY")
if not google_key:
    print("⚠️  警告：未找到 GOOGLE_API_KEY")

# 自訂兩位角色
print("\n👥 請設定第 1 位角色：")
role1_name = input("角色名稱（預設：會計顧問）: ").strip() or "會計顧問"
role1_backstory = input("背景描述（預設：擅長稅務與財務分析）: ").strip() or "擅長稅務與財務分析"
role1_task = input("任務說明（預設：從財務角度提供建議）: ").strip() or "從財務角度提供建議"

print("\n👥 請設定第 2 位角色：")
role2_name = input("角色名稱（預設：法律顧問）: ").strip() or "法律顧問"
role2_backstory = input("背景描述（預設：擅長公司法與合規分析）: ").strip() or "擅長公司法與合規分析"
role2_task = input("任務說明（預設：從法律角度提供建議）: ").strip() or "從法律角度提供建議"

# 啟動互動模式
conversation_history = []

while True:
    print("\n💬 請輸入您的會議問題（輸入 exit 結束）：")
    user_question = input("> ").strip()

    if user_question.lower() == "exit":
        print("\n👋 感謝使用 AI 助手！")
        break

    if not user_question:
        print("⚠️  請輸入非空白的問題。")
        continue

    try:
        print("🧠 建立多角色分析任務...")
        crew, task1, task2 = build_custom_crew(
            user_question=user_question,
            role1={
                "name": role1_name,
                "backstory": role1_backstory,
                "task": role1_task
            },
            role2={
                "name": role2_name,
                "backstory": role2_backstory,
                "task": role2_task
            }
        )

        print("🔍 分析中，請稍候...\n")
        result = crew.kickoff()

        # 儲存紀錄
        conversation_history.append({
            "question": user_question,
            "reply1": task1.output,
            "reply2": task2.output
        })

        print(f"🧑‍💼 {role1_name} 回覆：\n{task1.output}\n")
        print(f"🧑‍💼 {role2_name} 回覆：\n{task2.output}\n")

        # 總結紀錄
        print("📜 對話紀錄：")
        for idx, conv in enumerate(conversation_history, 1):
            print(f"{idx}. 問題：{conv['question']}")
            print(f"   {role1_name}：{conv['reply1'][:60]}...")
            print(f"   {role2_name}：{conv['reply2'][:60]}...\n")

    except Exception as e:
        print("\n❌ 發生錯誤：")
        print(f"錯誤類型：{type(e).__name__}")
        print(f"錯誤訊息：{e}")
        print("💡 檢查 API 金鑰與連線狀態")


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/__init__.py ===


=== ai_meeting_assistant/src/ai_meeting_assistant/tools/custom_tool.py ===
from crewai.tools import BaseTool
from typing import Type
from pydantic import BaseModel, Field


class MyCustomToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = (
        "Clear description for what this tool is useful for, your agent will need this information to use it."
    )
    args_schema: Type[BaseModel] = MyCustomToolInput

    def _run(self, argument: str) -> str:
        # Implementation goes here
        return "this is an example of a tool output, ignore it and move along."


=== ai_meeting_assistant/src/ai_meeting_assistant/config/agents.yaml ===
accountant:
  role: 會計師
  goal: 提供財務與稅務建議
  backstory: 擁有多年企業財務經驗的專業會計師，專精於稅務規劃與財務分析。

lawyer:
  role: 律師
  goal: 提供法律建議與合規分析
  backstory: 熟悉公司法與商業法律的律師，專注於企業合規與風險管理。


=== ai_meeting_assistant/src/ai_meeting_assistant/config/tasks.yaml ===
analyze_from_accounting:
  description: >
    使用者輸入的問題是：
    {user_question}

    你是一位會計師，請從財務與稅務角度提供建議與風險分析。
  expected_output: >
    詳細建議與說明
  agent: accountant


=== ai_meeting_assistant/src/ai_meeting_assistant/__pycache__/crew.cpython-311.pyc ===


=== ai_meeting_assistant/src/ai_meeting_assistant/__pycache__/crew.cpython-311.pyc ===
[無法讀取此檔案: 'utf-8' codec can't decode byte 0xa7 in position 0: invalid start byte]
